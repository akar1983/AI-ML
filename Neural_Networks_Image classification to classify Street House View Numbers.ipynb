{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Aug 10 2020 - Neural Networks Project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xdRC1ARs-Ul",
        "colab_type": "text"
      },
      "source": [
        "# Project - Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVTlq8O8QiqB",
        "colab_type": "text"
      },
      "source": [
        "### Submitted by - Abhik Kar\n",
        "\n",
        "##### Dated - 09-Aug-2020"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKrMNoD7Q-4H",
        "colab_type": "text"
      },
      "source": [
        "##### Description:\n",
        "The Street View House Numbers (SVHN) Dataset is a real-world image dataset for developing machine learning and object recognition algorithms with minimal requirement on data formatting but comes from a significantly harder, unsolved, real world problem (recognizing digits and numbers in natural scene images). SVHN is obtained from house numbers in Google Street View images.\n",
        "\n",
        "##### Objective:\n",
        "The objective of the project is to learn how to implement a simple image classification pipeline based on a deep neural network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N99JBbPVqQvQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "76430543-0d94-4512-b87a-e53d9c9b268c"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow\n",
        "tensorflow.__version__"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.3.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DCzXdTrvS43e",
        "colab_type": "text"
      },
      "source": [
        "#### Importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQ9d3QhGq3e7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import sklearn\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation\n",
        "from tensorflow.keras.layers import Dropout, BatchNormalization\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Ignore the warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYGbYvOlGayr",
        "colab_type": "text"
      },
      "source": [
        "## Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5pVMXg0q6dg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "da944fe4-00e3-43d4-a515-a2547ab28a53"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YG8lANStNHn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import h5py\n",
        "import numpy as np\n",
        "#Open the file as read only\n",
        "h5f = h5py.File('/content/drive/My Drive/Colab Notebooks/SVHN_single_grey1.h5','r')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RucAux66I5GZ",
        "colab_type": "text"
      },
      "source": [
        "## Data fetching and understand the training, validation and testing data splits"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCg7lgc5NOFi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "66d77ebc-56f4-433b-fd41-38419d36c881"
      },
      "source": [
        "h5f.keys()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<KeysViewHDF5 ['X_test', 'X_train', 'X_val', 'y_test', 'y_train', 'y_val']>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AesyfpxDNh3A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load the training, test and validation set\n",
        "X_train = h5f['X_train'][:]\n",
        "y_train = h5f['y_train'][:]\n",
        "X_val = h5f['X_val'][:]\n",
        "y_val = h5f['y_val'][:]\n",
        "X_test = h5f['X_test'][:]\n",
        "y_test = h5f['y_test'][:]\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fiQyi_iQSXi",
        "colab_type": "text"
      },
      "source": [
        "### Check the data shape"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIXJYwbECmg2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "1f8dfe1e-7940-442f-c127-516b30a71481"
      },
      "source": [
        "print(\"Shape of X_train:\",X_train.shape)\n",
        "print(\"Shape of y_train:\",y_train.shape)\n",
        "print(\"Shape of X_val:\",X_val.shape)\n",
        "print(\"Shape of y_val:\",y_val.shape)\n",
        "print(\"Shape of X_test:\",X_test.shape)\n",
        "print(\"Shape of y_test:\",y_test.shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of X_train: (42000, 32, 32)\n",
            "Shape of y_train: (42000,)\n",
            "Shape of X_val: (60000, 32, 32)\n",
            "Shape of y_val: (60000,)\n",
            "Shape of X_test: (18000, 32, 32)\n",
            "Shape of y_test: (18000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqMLvkVXJHmu",
        "colab_type": "text"
      },
      "source": [
        "## Basic Image Classification pipeline and the data-driven approach"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PSt0045SNsS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "a31c27c1-dbb0-492e-9426-7fcf62ce1039"
      },
      "source": [
        "print('First 5 examples training set are: ', y_train[0:5])\n",
        "print('First 5 examples validation set are: ', y_val[0:5])\n",
        "print('First 5 examples testing set are: ', y_test[0:5])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First 5 examples training set are:  [2 6 7 4 4]\n",
            "First 5 examples validation set are:  [0 0 0 0 0]\n",
            "First 5 examples testing set are:  [1 7 2 9 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgAY9xMQHLcb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "2ec0d985-4190-429b-e525-43e79023a18a"
      },
      "source": [
        "# show first number in the train dataset\n",
        "print(\"Label: {}\".format(y_train[0]))\n",
        "plt.imshow(X_train[0], cmap='gray')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label: 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fc9ce7cb8d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TN5a8_SxO3sV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "9e1ec39a-d388-4ad1-d45f-84e839653101"
      },
      "source": [
        "# show first number in the validation dataset\n",
        "print(\"Label: {}\".format(y_val[0]))\n",
        "plt.imshow(X_val[0], cmap='gray')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label: 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fc9ce2ad080>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwSzTJzxOjXu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "15b52221-db32-4c88-f0eb-446b3dd68102"
      },
      "source": [
        "# show first number in the test dataset\n",
        "print(\"Label: {}\".format(y_test[0]))\n",
        "plt.imshow(X_test[0], cmap='gray')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fc9ce2962b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGAVCpaqRViq",
        "colab_type": "text"
      },
      "source": [
        "### Data Pre-processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nordI9qdt5B-",
        "colab_type": "text"
      },
      "source": [
        "##### Normalize features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mytv2W0tJSDS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.astype('float32')\n",
        "X_val = X_val.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "X_train /= 255\n",
        "X_val /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCEJciLzuCH5",
        "colab_type": "text"
      },
      "source": [
        "##### Reshape features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBPwcljzRWLO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# reshaping X data: (n, 32, 32) => (n, 1024)\n",
        "X_train = X_train.reshape((X_train.shape[0], -1))\n",
        "X_val = X_val.reshape((X_val.shape[0], -1))\n",
        "X_test = X_test.reshape((X_test.shape[0], -1))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8Rrca0K2KCk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "74dffab1-c4af-4aa1-fd9d-d5335bab4c7e"
      },
      "source": [
        "print(X_train.shape, X_val.shape, X_test.shape, y_train.shape, y_val.shape, y_test.shape)\n",
        "\n",
        "print(\"Images in X_train:\", X_train.shape[0])\n",
        "print(\"Images in X_val:\", X_val.shape[0])\n",
        "print(\"Images in X_test:\", X_test.shape[0])\n",
        "\n",
        "print(\"Max value in X_train:\", X_train.max())\n",
        "print(\"Min value in X_train:\", X_train.min())\n",
        "print(\"Max value in X_val:\", X_val.max())\n",
        "print(\"Min value in X_val:\", X_val.min())\n",
        "print(\"Max value in X_test:\", X_test.max())\n",
        "print(\"Min value in X_test:\", X_test.min())"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(42000, 1024) (60000, 1024) (18000, 1024) (42000,) (60000,) (18000,)\n",
            "Images in X_train: 42000\n",
            "Images in X_val: 60000\n",
            "Images in X_test: 18000\n",
            "Max value in X_train: 0.9999\n",
            "Min value in X_train: 0.0\n",
            "Max value in X_val: 0.9999\n",
            "Min value in X_val: 0.0\n",
            "Max value in X_test: 0.9999\n",
            "Min value in X_test: 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IkK_Vo-2U4Qe",
        "colab_type": "text"
      },
      "source": [
        "## One-hot encode the class vector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iol_TFtZRmQX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "558370c7-b5d1-4f6d-a85f-84a0dfa26dd2"
      },
      "source": [
        "print(\"Value of first number in training set before encoding :\", y_train[10])\n",
        "print(\"Value of first number in validation set before encoding:\", y_val[10])\n",
        "print(\"Value of first number in testing set before encoding:\", y_test[10])\n",
        "y_train = to_categorical(y_train, num_classes=10)\n",
        "y_val = to_categorical(y_val, num_classes=10)\n",
        "y_test = to_categorical(y_test, num_classes=10)\n",
        "\n",
        "print(\"Shape of y_train:\", y_train.shape)\n",
        "print(\"One hot encoded value of y_train first number:\", y_train[10])\n",
        "print(\"Shape of y_val:\", y_val.shape)\n",
        "print(\"One hot encoded value of y_val first number:\", y_val[10])\n",
        "print(\"Shape of y_test:\", y_test.shape)\n",
        "print(\"One hot encoded value of y_test first number:\", y_test[10])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Value of first number in training set before encoding : 1\n",
            "Value of first number in validation set before encoding: 0\n",
            "Value of first number in testing set before encoding: 8\n",
            "Shape of y_train: (42000, 10)\n",
            "One hot encoded value of y_train first number: [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "Shape of y_val: (60000, 10)\n",
            "One hot encoded value of y_val first number: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "Shape of y_test: (18000, 10)\n",
            "One hot encoded value of y_test first number: [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lzt3w3Lz6mr",
        "colab_type": "text"
      },
      "source": [
        "## Scaling data for better performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_jLOnGRz586",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Scalaing\n",
        "sc=StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_val = sc.fit_transform(X_val)\n",
        "X_test = sc.fit_transform(X_test)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emHJI_Cmrxih",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "outputId": "c545b26d-2d0e-4326-ab7e-b15e2ed27fc5"
      },
      "source": [
        "# visualizing the first 10 images in the dataset and their labels\n",
        "plt.figure(figsize=(10, 1))\n",
        "for i in range(10):\n",
        "    plt.subplot(1, 10, i+1)\n",
        "    plt.imshow(X_train[i].reshape(32, 32), cmap=\"gray\")\n",
        "    plt.axis('off')\n",
        "    print('label for each of the below image: %s' % (np.argmax(y_train[0:10][i])))\n",
        "plt.show()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "label for each of the below image: 2\n",
            "label for each of the below image: 6\n",
            "label for each of the below image: 7\n",
            "label for each of the below image: 4\n",
            "label for each of the below image: 4\n",
            "label for each of the below image: 0\n",
            "label for each of the below image: 3\n",
            "label for each of the below image: 0\n",
            "label for each of the below image: 7\n",
            "label for each of the below image: 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x72 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THtMV5zjFcQv",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5tL7d0fq2i1h",
        "colab_type": "text"
      },
      "source": [
        "## Implement and apply a deep neural network classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0oEYB1g2zYE",
        "colab_type": "text"
      },
      "source": [
        "#### Feedforward Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvKGcWJb2-_p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  model = Sequential()\n",
        "  model.add(Dense(128, input_shape = (1024, )))\n",
        "  model.add(Activation('sigmoid'))\n",
        "  model.add(Dense(128, activation=\"sigmoid\"))\n",
        "  model.add(Dense(10, activation=\"softmax\"))"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVJXbghX3RiB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sgd = optimizers.SGD(lr = 0.001)\n",
        "model.compile(optimizer = sgd, loss = 'categorical_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGRst5F8JRyJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "620bb1b2-18c7-4eff-b227-9ad72d1ac3ca"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 128)               131200    \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 149,002\n",
            "Trainable params: 149,002\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQR8PIqw3k8F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "outputId": "2a6014e9-6693-4d37-d7b0-73f5f41703cc"
      },
      "source": [
        "model_fit = model.fit(X_train, y_train, batch_size=200, epochs = 20, verbose = 1)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 2.4001 - accuracy: 0.1008\n",
            "Epoch 2/20\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 2.3223 - accuracy: 0.1001\n",
            "Epoch 3/20\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 2.3081 - accuracy: 0.0978\n",
            "Epoch 4/20\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 2.3051 - accuracy: 0.0965\n",
            "Epoch 5/20\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 2.3045 - accuracy: 0.0976\n",
            "Epoch 6/20\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 2.3042 - accuracy: 0.1006\n",
            "Epoch 7/20\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 2.3041 - accuracy: 0.1015\n",
            "Epoch 8/20\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 2.3040 - accuracy: 0.1015\n",
            "Epoch 9/20\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 2.3039 - accuracy: 0.1017\n",
            "Epoch 10/20\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 2.3039 - accuracy: 0.1017\n",
            "Epoch 11/20\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 2.3038 - accuracy: 0.1043\n",
            "Epoch 12/20\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 2.3037 - accuracy: 0.1035\n",
            "Epoch 13/20\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 2.3036 - accuracy: 0.1014\n",
            "Epoch 14/20\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 2.3035 - accuracy: 0.1049\n",
            "Epoch 15/20\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 2.3035 - accuracy: 0.1034\n",
            "Epoch 16/20\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 2.3034 - accuracy: 0.1040\n",
            "Epoch 17/20\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 2.3033 - accuracy: 0.1065\n",
            "Epoch 18/20\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 2.3033 - accuracy: 0.1059\n",
            "Epoch 19/20\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 2.3032 - accuracy: 0.1044\n",
            "Epoch 20/20\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 2.3031 - accuracy: 0.1055\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64dGTj464oaG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "fd80c0fd-b0a5-473f-ff4f-85925b8a64f0"
      },
      "source": [
        "model.evaluate(X_val, y_val)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1875/1875 [==============================] - 4s 2ms/step - loss: 2.3032 - accuracy: 0.1049\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.3032259941101074, 0.10490000247955322]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCOfbg8A366Q",
        "colab_type": "text"
      },
      "source": [
        "With just Feedforward Neural Network and having Activation function as Sigmoid with Learning Rate 0.01 accuracy is very low 10% only and loss is also high 2.3\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4uqd8_e3xYVP",
        "colab_type": "text"
      },
      "source": [
        "### Weight Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TP15mAIA5hjc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mlp_model():\n",
        "    model = Sequential()\n",
        "    \n",
        "    model.add(Dense(128, input_shape = (1024, ), kernel_initializer='he_normal'))     # use he_normal initializer\n",
        "    model.add(Activation('sigmoid'))    \n",
        "    model.add(Dense(128, kernel_initializer='he_normal'))                            # use he_normal initializer\n",
        "    model.add(Activation('sigmoid'))    \n",
        "    model.add(Dense(10, kernel_initializer='he_normal'))                            # use he_normal initializer\n",
        "    model.add(Activation('softmax'))\n",
        "\n",
        "    sgd = optimizers.SGD(lr = 0.001)\n",
        "    model.compile(optimizer = sgd, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DgjkmofQ6aCg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "outputId": "a41979ea-b809-4191-e080-adf9aabd5b4e"
      },
      "source": [
        "model = mlp_model()\n",
        "model_fit = model.fit(X_train, y_train, batch_size=200, epochs = 20, verbose = 1)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 2.4440 - accuracy: 0.1019\n",
            "Epoch 2/20\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 2.3465 - accuracy: 0.1055\n",
            "Epoch 3/20\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 2.3176 - accuracy: 0.1091\n",
            "Epoch 4/20\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 2.3094 - accuracy: 0.1120\n",
            "Epoch 5/20\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 2.3072 - accuracy: 0.1085\n",
            "Epoch 6/20\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 2.3063 - accuracy: 0.1078\n",
            "Epoch 7/20\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 2.3058 - accuracy: 0.1082\n",
            "Epoch 8/20\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 2.3054 - accuracy: 0.1081\n",
            "Epoch 9/20\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 2.3050 - accuracy: 0.1078\n",
            "Epoch 10/20\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 2.3047 - accuracy: 0.1093\n",
            "Epoch 11/20\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 2.3044 - accuracy: 0.1081\n",
            "Epoch 12/20\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 2.3042 - accuracy: 0.1090\n",
            "Epoch 13/20\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 2.3039 - accuracy: 0.1091\n",
            "Epoch 14/20\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 2.3037 - accuracy: 0.1090\n",
            "Epoch 15/20\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 2.3035 - accuracy: 0.1096\n",
            "Epoch 16/20\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 2.3033 - accuracy: 0.1100\n",
            "Epoch 17/20\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 2.3031 - accuracy: 0.1103\n",
            "Epoch 18/20\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 2.3029 - accuracy: 0.1103\n",
            "Epoch 19/20\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 2.3027 - accuracy: 0.1102\n",
            "Epoch 20/20\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.1116\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2AZ2Vt097qiZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "7acc43d6-b14d-4a42-bc73-20539305bb70"
      },
      "source": [
        "model.evaluate(X_val, y_val)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1875/1875 [==============================] - 4s 2ms/step - loss: 2.3027 - accuracy: 0.1110\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.302651882171631, 0.11103333532810211]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gl0YwMCb7vKv",
        "colab_type": "text"
      },
      "source": [
        "With just Feedforward Neural Network and having Activation function as Sigmoid with Learning Rate 0.01 accuracy is very low 11% only and loss is also high 2.3. This is because Sigmoid function suffers from gradient vanishing problem, making training slower."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2uFU16FqZ_RQ",
        "colab_type": "text"
      },
      "source": [
        "## Apply ReLU (Rectified Linear Unit)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Okanjx2Q8JZe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mlp_model():\n",
        "    model = Sequential()\n",
        "    \n",
        "    model.add(Dense(128, input_shape = (1024, ), kernel_initializer='he_normal'))     # use he_normal initializer\n",
        "    model.add(Activation('relu'))    \n",
        "    model.add(Dense(128, kernel_initializer='he_normal'))                            # use he_normal initializer\n",
        "    model.add(Activation('relu'))    \n",
        "    model.add(Dense(10, kernel_initializer='he_normal'))                            # use he_normal initializer\n",
        "    model.add(Activation('softmax'))\n",
        "\n",
        "    sgd = optimizers.SGD(lr = 0.001)\n",
        "    model.compile(optimizer = sgd, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSmfMrU68kqw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c21ada2c-0cd0-4171-e910-7dead86a1cfd"
      },
      "source": [
        "model = mlp_model()\n",
        "\n",
        "model_fit = model.fit(X_train, y_train, batch_size=200, epochs = 100, verbose = 1)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 2.5495 - accuracy: 0.1121\n",
            "Epoch 2/100\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 2.3641 - accuracy: 0.1379\n",
            "Epoch 3/100\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 2.2904 - accuracy: 0.1662\n",
            "Epoch 4/100\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 2.2341 - accuracy: 0.1927\n",
            "Epoch 5/100\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 2.1848 - accuracy: 0.2201\n",
            "Epoch 6/100\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 2.1392 - accuracy: 0.2458\n",
            "Epoch 7/100\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 2.0949 - accuracy: 0.2712\n",
            "Epoch 8/100\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 2.0509 - accuracy: 0.2962\n",
            "Epoch 9/100\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 2.0072 - accuracy: 0.3202\n",
            "Epoch 10/100\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 1.9634 - accuracy: 0.3440\n",
            "Epoch 11/100\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 1.9198 - accuracy: 0.3657\n",
            "Epoch 12/100\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 1.8762 - accuracy: 0.3869\n",
            "Epoch 13/100\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 1.8333 - accuracy: 0.4097\n",
            "Epoch 14/100\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 1.7913 - accuracy: 0.4295\n",
            "Epoch 15/100\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 1.7501 - accuracy: 0.4480\n",
            "Epoch 16/100\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 1.7103 - accuracy: 0.4652\n",
            "Epoch 17/100\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 1.6721 - accuracy: 0.4814\n",
            "Epoch 18/100\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 1.6353 - accuracy: 0.4964\n",
            "Epoch 19/100\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 1.6003 - accuracy: 0.5120\n",
            "Epoch 20/100\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 1.5671 - accuracy: 0.5246\n",
            "Epoch 21/100\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 1.5354 - accuracy: 0.5368\n",
            "Epoch 22/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 1.5058 - accuracy: 0.5471\n",
            "Epoch 23/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 1.4775 - accuracy: 0.5587\n",
            "Epoch 24/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 1.4508 - accuracy: 0.5685\n",
            "Epoch 25/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 1.4254 - accuracy: 0.5775\n",
            "Epoch 26/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 1.4014 - accuracy: 0.5860\n",
            "Epoch 27/100\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 1.3786 - accuracy: 0.5953\n",
            "Epoch 28/100\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 1.3569 - accuracy: 0.6029\n",
            "Epoch 29/100\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 1.3365 - accuracy: 0.6094\n",
            "Epoch 30/100\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 1.3169 - accuracy: 0.6154\n",
            "Epoch 31/100\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 1.2986 - accuracy: 0.6216\n",
            "Epoch 32/100\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 1.2811 - accuracy: 0.6263\n",
            "Epoch 33/100\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 1.2645 - accuracy: 0.6319\n",
            "Epoch 34/100\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 1.2487 - accuracy: 0.6371\n",
            "Epoch 35/100\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 1.2337 - accuracy: 0.6417\n",
            "Epoch 36/100\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 1.2193 - accuracy: 0.6463\n",
            "Epoch 37/100\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 1.2057 - accuracy: 0.6508\n",
            "Epoch 38/100\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 1.1927 - accuracy: 0.6543\n",
            "Epoch 39/100\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 1.1802 - accuracy: 0.6576\n",
            "Epoch 40/100\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 1.1682 - accuracy: 0.6620\n",
            "Epoch 41/100\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 1.1568 - accuracy: 0.6660\n",
            "Epoch 42/100\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 1.1458 - accuracy: 0.6693\n",
            "Epoch 43/100\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 1.1351 - accuracy: 0.6720\n",
            "Epoch 44/100\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 1.1250 - accuracy: 0.6745\n",
            "Epoch 45/100\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 1.1151 - accuracy: 0.6780\n",
            "Epoch 46/100\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 1.1057 - accuracy: 0.6805\n",
            "Epoch 47/100\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 1.0965 - accuracy: 0.6832\n",
            "Epoch 48/100\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 1.0877 - accuracy: 0.6850\n",
            "Epoch 49/100\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 1.0791 - accuracy: 0.6885\n",
            "Epoch 50/100\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 1.0706 - accuracy: 0.6915\n",
            "Epoch 51/100\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 1.0626 - accuracy: 0.6936\n",
            "Epoch 52/100\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 1.0549 - accuracy: 0.6956\n",
            "Epoch 53/100\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 1.0471 - accuracy: 0.6980\n",
            "Epoch 54/100\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 1.0398 - accuracy: 0.7002\n",
            "Epoch 55/100\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 1.0325 - accuracy: 0.7030\n",
            "Epoch 56/100\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 1.0257 - accuracy: 0.7049\n",
            "Epoch 57/100\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 1.0188 - accuracy: 0.7064\n",
            "Epoch 58/100\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 1.0122 - accuracy: 0.7085\n",
            "Epoch 59/100\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 1.0058 - accuracy: 0.7107\n",
            "Epoch 60/100\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 0.9995 - accuracy: 0.7122\n",
            "Epoch 61/100\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 0.9933 - accuracy: 0.7141\n",
            "Epoch 62/100\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 0.9874 - accuracy: 0.7162\n",
            "Epoch 63/100\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 0.9815 - accuracy: 0.7176\n",
            "Epoch 64/100\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 0.9758 - accuracy: 0.7188\n",
            "Epoch 65/100\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 0.9700 - accuracy: 0.7196\n",
            "Epoch 66/100\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 0.9647 - accuracy: 0.7220\n",
            "Epoch 67/100\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 0.9592 - accuracy: 0.7240\n",
            "Epoch 68/100\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 0.9539 - accuracy: 0.7247\n",
            "Epoch 69/100\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 0.9488 - accuracy: 0.7260\n",
            "Epoch 70/100\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 0.9436 - accuracy: 0.7281\n",
            "Epoch 71/100\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 0.9386 - accuracy: 0.7298\n",
            "Epoch 72/100\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 0.9337 - accuracy: 0.7308\n",
            "Epoch 73/100\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 0.9289 - accuracy: 0.7327\n",
            "Epoch 74/100\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 0.9241 - accuracy: 0.7337\n",
            "Epoch 75/100\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 0.9195 - accuracy: 0.7342\n",
            "Epoch 76/100\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 0.9149 - accuracy: 0.7359\n",
            "Epoch 77/100\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 0.9105 - accuracy: 0.7374\n",
            "Epoch 78/100\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 0.9061 - accuracy: 0.7380\n",
            "Epoch 79/100\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 0.9017 - accuracy: 0.7393\n",
            "Epoch 80/100\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 0.8975 - accuracy: 0.7400\n",
            "Epoch 81/100\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 0.8932 - accuracy: 0.7420\n",
            "Epoch 82/100\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 0.8890 - accuracy: 0.7425\n",
            "Epoch 83/100\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 0.8849 - accuracy: 0.7440\n",
            "Epoch 84/100\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 0.8809 - accuracy: 0.7449\n",
            "Epoch 85/100\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 0.8770 - accuracy: 0.7467\n",
            "Epoch 86/100\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 0.8731 - accuracy: 0.7470\n",
            "Epoch 87/100\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 0.8692 - accuracy: 0.7485\n",
            "Epoch 88/100\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 0.8654 - accuracy: 0.7496\n",
            "Epoch 89/100\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 0.8617 - accuracy: 0.7508\n",
            "Epoch 90/100\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 0.8580 - accuracy: 0.7517\n",
            "Epoch 91/100\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 0.8544 - accuracy: 0.7528\n",
            "Epoch 92/100\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 0.8508 - accuracy: 0.7541\n",
            "Epoch 93/100\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 0.8472 - accuracy: 0.7542\n",
            "Epoch 94/100\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 0.8437 - accuracy: 0.7560\n",
            "Epoch 95/100\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 0.8403 - accuracy: 0.7564\n",
            "Epoch 96/100\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 0.8371 - accuracy: 0.7574\n",
            "Epoch 97/100\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 0.8336 - accuracy: 0.7588\n",
            "Epoch 98/100\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 0.8304 - accuracy: 0.7593\n",
            "Epoch 99/100\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 0.8271 - accuracy: 0.7607\n",
            "Epoch 100/100\n",
            "210/210 [==============================] - 1s 3ms/step - loss: 0.8238 - accuracy: 0.7616\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rniszyDI-gYg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ddcb8433-d6b1-402d-b82e-35de839fb7aa"
      },
      "source": [
        "results = model.evaluate(X_val, y_val)\n",
        "print('Val_acc using simple NN SGD : ', results[1])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.8385 - accuracy: 0.7570\n",
            "Val_acc using simple NN SGD :  0.7569500207901001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9UQpSlpZZj5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "0d107c25-81a3-4f5e-b8c4-5fe7b3b34645"
      },
      "source": [
        "#Store the accuracy results for each model in a dataframe for final comparison\n",
        "results_on_val = pd.DataFrame({'Method':['NN SDG'], 'accuracy': results[1]},index={'1'})\n",
        "results_on_val = results_on_val[['Method', 'accuracy']]\n",
        "results_on_val"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Method</th>\n",
              "      <th>accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NN SDG</td>\n",
              "      <td>0.75695</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Method  accuracy\n",
              "1  NN SDG   0.75695"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17jXDn6a-D_s",
        "colab_type": "text"
      },
      "source": [
        "Great improvement in training the model with Nonlinearity Activation function ReLU. Even though we didn't change the Learning Rate 0.001. The accuracy bumped up significantly and loss is also reduced derastically using ReLU."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fv2c6W6Y-8W3",
        "colab_type": "text"
      },
      "source": [
        "## Implement Batch Normalization for training the neural network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDmaIPoK--NA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Batch normalization layer is inserted after dense/convolution and before nonlinearity\n",
        "def mlp_model():\n",
        "    model = Sequential()\n",
        "    \n",
        "    model.add(Dense(128, input_shape = (1024, ), kernel_initializer='he_normal'))     # use he_normal initializer\n",
        "    model.add(BatchNormalization()) \n",
        "    model.add(Activation('relu'))    \n",
        "    model.add(Dense(128, kernel_initializer='he_normal'))                            # use he_normal initializer\n",
        "    model.add(BatchNormalization()) \n",
        "    model.add(Activation('relu'))    \n",
        "    model.add(Dense(10, kernel_initializer='he_normal'))                            # use he_normal initializer\n",
        "    model.add(Activation('softmax'))\n",
        "\n",
        "    sgd = optimizers.SGD(lr = 0.001)\n",
        "    model.compile(optimizer = sgd, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLh71doH_mar",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "baad5b49-664d-4dac-af26-bf5bb30f0eee"
      },
      "source": [
        "model = mlp_model()\n",
        "model_fit = model.fit(X_train, y_train, batch_size=200, epochs = 100, verbose = 1)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 2.5678 - accuracy: 0.1159\n",
            "Epoch 2/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 2.4154 - accuracy: 0.1400\n",
            "Epoch 3/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 2.3295 - accuracy: 0.1625\n",
            "Epoch 4/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 2.2664 - accuracy: 0.1853\n",
            "Epoch 5/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 2.2148 - accuracy: 0.2065\n",
            "Epoch 6/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 2.1705 - accuracy: 0.2291\n",
            "Epoch 7/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 2.1295 - accuracy: 0.2479\n",
            "Epoch 8/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 2.0893 - accuracy: 0.2698\n",
            "Epoch 9/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 2.0519 - accuracy: 0.2905\n",
            "Epoch 10/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 2.0162 - accuracy: 0.3105\n",
            "Epoch 11/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 1.9807 - accuracy: 0.3290\n",
            "Epoch 12/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 1.9473 - accuracy: 0.3476\n",
            "Epoch 13/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 1.9135 - accuracy: 0.3661\n",
            "Epoch 14/100\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 1.8802 - accuracy: 0.3827\n",
            "Epoch 15/100\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 1.8511 - accuracy: 0.3971\n",
            "Epoch 16/100\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 1.8200 - accuracy: 0.4151\n",
            "Epoch 17/100\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 1.7911 - accuracy: 0.4295\n",
            "Epoch 18/100\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 1.7617 - accuracy: 0.4448\n",
            "Epoch 19/100\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 1.7348 - accuracy: 0.4575\n",
            "Epoch 20/100\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 1.7086 - accuracy: 0.4693\n",
            "Epoch 21/100\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 1.6837 - accuracy: 0.4830\n",
            "Epoch 22/100\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 1.6592 - accuracy: 0.4939\n",
            "Epoch 23/100\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 1.6344 - accuracy: 0.5057\n",
            "Epoch 24/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 1.6102 - accuracy: 0.5157\n",
            "Epoch 25/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 1.5879 - accuracy: 0.5265\n",
            "Epoch 26/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 1.5657 - accuracy: 0.5381\n",
            "Epoch 27/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 1.5438 - accuracy: 0.5437\n",
            "Epoch 28/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 1.5217 - accuracy: 0.5537\n",
            "Epoch 29/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 1.5032 - accuracy: 0.5640\n",
            "Epoch 30/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 1.4827 - accuracy: 0.5688\n",
            "Epoch 31/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 1.4645 - accuracy: 0.5773\n",
            "Epoch 32/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 1.4447 - accuracy: 0.5869\n",
            "Epoch 33/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 1.4292 - accuracy: 0.5904\n",
            "Epoch 34/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 1.4100 - accuracy: 0.5989\n",
            "Epoch 35/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 1.3920 - accuracy: 0.6025\n",
            "Epoch 36/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 1.3779 - accuracy: 0.6102\n",
            "Epoch 37/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 1.3620 - accuracy: 0.6145\n",
            "Epoch 38/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 1.3462 - accuracy: 0.6205\n",
            "Epoch 39/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 1.3309 - accuracy: 0.6242\n",
            "Epoch 40/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 1.3152 - accuracy: 0.6305\n",
            "Epoch 41/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 1.3014 - accuracy: 0.6354\n",
            "Epoch 42/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 1.2895 - accuracy: 0.6379\n",
            "Epoch 43/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 1.2759 - accuracy: 0.6420\n",
            "Epoch 44/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 1.2613 - accuracy: 0.6479\n",
            "Epoch 45/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 1.2503 - accuracy: 0.6495\n",
            "Epoch 46/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 1.2381 - accuracy: 0.6529\n",
            "Epoch 47/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 1.2270 - accuracy: 0.6567\n",
            "Epoch 48/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 1.2137 - accuracy: 0.6624\n",
            "Epoch 49/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 1.2047 - accuracy: 0.6638\n",
            "Epoch 50/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 1.1937 - accuracy: 0.6663\n",
            "Epoch 51/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 1.1813 - accuracy: 0.6712\n",
            "Epoch 52/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 1.1732 - accuracy: 0.6713\n",
            "Epoch 53/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 1.1633 - accuracy: 0.6755\n",
            "Epoch 54/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 1.1530 - accuracy: 0.6799\n",
            "Epoch 55/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 1.1448 - accuracy: 0.6788\n",
            "Epoch 56/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 1.1336 - accuracy: 0.6825\n",
            "Epoch 57/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 1.1246 - accuracy: 0.6850\n",
            "Epoch 58/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 1.1165 - accuracy: 0.6878\n",
            "Epoch 59/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 1.1078 - accuracy: 0.6937\n",
            "Epoch 60/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 1.1006 - accuracy: 0.6925\n",
            "Epoch 61/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 1.0906 - accuracy: 0.6948\n",
            "Epoch 62/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 1.0842 - accuracy: 0.6965\n",
            "Epoch 63/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 1.0772 - accuracy: 0.6985\n",
            "Epoch 64/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 1.0696 - accuracy: 0.6983\n",
            "Epoch 65/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 1.0614 - accuracy: 0.7035\n",
            "Epoch 66/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 1.0557 - accuracy: 0.7047\n",
            "Epoch 67/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 1.0456 - accuracy: 0.7080\n",
            "Epoch 68/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 1.0395 - accuracy: 0.7079\n",
            "Epoch 69/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 1.0322 - accuracy: 0.7107\n",
            "Epoch 70/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 1.0266 - accuracy: 0.7108\n",
            "Epoch 71/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 1.0191 - accuracy: 0.7132\n",
            "Epoch 72/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 1.0149 - accuracy: 0.7144\n",
            "Epoch 73/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 1.0065 - accuracy: 0.7167\n",
            "Epoch 74/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 1.0011 - accuracy: 0.7183\n",
            "Epoch 75/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.9961 - accuracy: 0.7195\n",
            "Epoch 76/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.9888 - accuracy: 0.7219\n",
            "Epoch 77/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.9824 - accuracy: 0.7232\n",
            "Epoch 78/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.9774 - accuracy: 0.7248\n",
            "Epoch 79/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.9715 - accuracy: 0.7252\n",
            "Epoch 80/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.9659 - accuracy: 0.7266\n",
            "Epoch 81/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.9604 - accuracy: 0.7292\n",
            "Epoch 82/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.9535 - accuracy: 0.7298\n",
            "Epoch 83/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.9507 - accuracy: 0.7305\n",
            "Epoch 84/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.9429 - accuracy: 0.7320\n",
            "Epoch 85/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.9400 - accuracy: 0.7333\n",
            "Epoch 86/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.9340 - accuracy: 0.7346\n",
            "Epoch 87/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.9310 - accuracy: 0.7354\n",
            "Epoch 88/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.9238 - accuracy: 0.7369\n",
            "Epoch 89/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.9188 - accuracy: 0.7400\n",
            "Epoch 90/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.9146 - accuracy: 0.7389\n",
            "Epoch 91/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.9117 - accuracy: 0.7422\n",
            "Epoch 92/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.9057 - accuracy: 0.7426\n",
            "Epoch 93/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.9008 - accuracy: 0.7438\n",
            "Epoch 94/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.8967 - accuracy: 0.7463\n",
            "Epoch 95/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.8907 - accuracy: 0.7467\n",
            "Epoch 96/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.8876 - accuracy: 0.7458\n",
            "Epoch 97/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.8829 - accuracy: 0.7477\n",
            "Epoch 98/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.8778 - accuracy: 0.7490\n",
            "Epoch 99/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.8740 - accuracy: 0.7505\n",
            "Epoch 100/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.8700 - accuracy: 0.7515\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-OKIEO3DkWa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f5925e52-4477-4e85-e7c9-421f3b6ae871"
      },
      "source": [
        "results = model.evaluate(X_val, y_val)\n",
        "print('Val_acc using NN SGD (Batch Normalization) : ', results[1])"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.8615 - accuracy: 0.7570\n",
            "Val_acc using NN SGD (Batch Normalization) :  0.7569666504859924\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-RLQp72ghDm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "outputId": "765f90a0-03be-4370-ae42-b9eda2203a2d"
      },
      "source": [
        "#Store the accuracy results for each model in a dataframe for final comparison\n",
        "tempResultsDf = pd.DataFrame({'Method':['NN SGD (Batch Normalization)'], 'accuracy': [results[1]]},index={'2'})\n",
        "results_on_val= pd.concat([results_on_val, tempResultsDf])\n",
        "results_on_val = results_on_val[['Method', 'accuracy']]\n",
        "results_on_val"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Method</th>\n",
              "      <th>accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NN SDG</td>\n",
              "      <td>0.756950</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NN SGD (Batch Normalization)</td>\n",
              "      <td>0.756967</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                         Method  accuracy\n",
              "1                        NN SDG  0.756950\n",
              "2  NN SGD (Batch Normalization)  0.756967"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6KpPsGSNHeor",
        "colab_type": "text"
      },
      "source": [
        "#### Using ADAM Optimizer inplace of SGD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxekVc4nHlJ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Batch normalization layer is inserted after dense/convolution and before nonlinearity\n",
        "def mlp_model():\n",
        "    model = Sequential()\n",
        "    \n",
        "    model.add(Dense(128, input_shape = (1024, ), kernel_initializer='he_normal'))     # use he_normal initializer\n",
        "    model.add(BatchNormalization()) \n",
        "    model.add(Activation('relu'))    \n",
        "    model.add(Dense(128, kernel_initializer='he_normal'))                            # use he_normal initializer\n",
        "    model.add(BatchNormalization()) \n",
        "    model.add(Activation('relu'))    \n",
        "    model.add(Dense(10, kernel_initializer='he_normal'))                            # use he_normal initializer\n",
        "    model.add(Activation('softmax'))\n",
        "    \n",
        "    adam = optimizers.Adam(lr = 0.001)\n",
        "    model.compile(optimizer = adam, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uO7W4U7IHj1R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7133e826-5c17-4412-901d-fc7df410df8d"
      },
      "source": [
        "model = mlp_model()\n",
        "model_fit = model.fit(X_train, y_train, batch_size=200, epochs = 100, verbose = 1)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 1.3926 - accuracy: 0.5661\n",
            "Epoch 2/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.8859 - accuracy: 0.7315\n",
            "Epoch 3/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.7505 - accuracy: 0.7697\n",
            "Epoch 4/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.6674 - accuracy: 0.7965\n",
            "Epoch 5/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.6158 - accuracy: 0.8100\n",
            "Epoch 6/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.5712 - accuracy: 0.8253\n",
            "Epoch 7/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.5384 - accuracy: 0.8325\n",
            "Epoch 8/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.5133 - accuracy: 0.8393\n",
            "Epoch 9/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.4943 - accuracy: 0.8463\n",
            "Epoch 10/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.4764 - accuracy: 0.8515\n",
            "Epoch 11/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.4447 - accuracy: 0.8620\n",
            "Epoch 12/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.4362 - accuracy: 0.8640\n",
            "Epoch 13/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.4206 - accuracy: 0.8693\n",
            "Epoch 14/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.4093 - accuracy: 0.8721\n",
            "Epoch 15/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3985 - accuracy: 0.8740\n",
            "Epoch 16/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3841 - accuracy: 0.8795\n",
            "Epoch 17/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3754 - accuracy: 0.8816\n",
            "Epoch 18/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3729 - accuracy: 0.8810\n",
            "Epoch 19/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3481 - accuracy: 0.8911\n",
            "Epoch 20/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3519 - accuracy: 0.8886\n",
            "Epoch 21/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3306 - accuracy: 0.8976\n",
            "Epoch 22/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3260 - accuracy: 0.8971\n",
            "Epoch 23/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3256 - accuracy: 0.8970\n",
            "Epoch 24/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3160 - accuracy: 0.9003\n",
            "Epoch 25/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3072 - accuracy: 0.9033\n",
            "Epoch 26/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3019 - accuracy: 0.9026\n",
            "Epoch 27/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2977 - accuracy: 0.9053\n",
            "Epoch 28/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2933 - accuracy: 0.9056\n",
            "Epoch 29/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2789 - accuracy: 0.9122\n",
            "Epoch 30/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2807 - accuracy: 0.9098\n",
            "Epoch 31/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2718 - accuracy: 0.9135\n",
            "Epoch 32/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2705 - accuracy: 0.9139\n",
            "Epoch 33/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2614 - accuracy: 0.9171\n",
            "Epoch 34/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2512 - accuracy: 0.9212\n",
            "Epoch 35/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2621 - accuracy: 0.9149\n",
            "Epoch 36/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2443 - accuracy: 0.9204\n",
            "Epoch 37/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2368 - accuracy: 0.9232\n",
            "Epoch 38/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2372 - accuracy: 0.9251\n",
            "Epoch 39/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2379 - accuracy: 0.9242\n",
            "Epoch 40/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2378 - accuracy: 0.9245\n",
            "Epoch 41/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2251 - accuracy: 0.9284\n",
            "Epoch 42/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2262 - accuracy: 0.9267\n",
            "Epoch 43/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2211 - accuracy: 0.9297\n",
            "Epoch 44/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2125 - accuracy: 0.9310\n",
            "Epoch 45/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2126 - accuracy: 0.9295\n",
            "Epoch 46/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2051 - accuracy: 0.9348\n",
            "Epoch 47/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2072 - accuracy: 0.9324\n",
            "Epoch 48/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1993 - accuracy: 0.9344\n",
            "Epoch 49/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1980 - accuracy: 0.9358\n",
            "Epoch 50/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1983 - accuracy: 0.9355\n",
            "Epoch 51/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1943 - accuracy: 0.9361\n",
            "Epoch 52/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1857 - accuracy: 0.9403\n",
            "Epoch 53/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1868 - accuracy: 0.9389\n",
            "Epoch 54/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1890 - accuracy: 0.9392\n",
            "Epoch 55/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1746 - accuracy: 0.9437\n",
            "Epoch 56/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1784 - accuracy: 0.9418\n",
            "Epoch 57/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1783 - accuracy: 0.9406\n",
            "Epoch 58/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1823 - accuracy: 0.9412\n",
            "Epoch 59/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1666 - accuracy: 0.9462\n",
            "Epoch 60/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1735 - accuracy: 0.9430\n",
            "Epoch 61/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1630 - accuracy: 0.9471\n",
            "Epoch 62/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1739 - accuracy: 0.9430\n",
            "Epoch 63/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1659 - accuracy: 0.9449\n",
            "Epoch 64/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1663 - accuracy: 0.9445\n",
            "Epoch 65/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1666 - accuracy: 0.9458\n",
            "Epoch 66/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1553 - accuracy: 0.9506\n",
            "Epoch 67/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1516 - accuracy: 0.9500\n",
            "Epoch 68/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1586 - accuracy: 0.9474\n",
            "Epoch 69/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1500 - accuracy: 0.9495\n",
            "Epoch 70/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1445 - accuracy: 0.9526\n",
            "Epoch 71/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1521 - accuracy: 0.9505\n",
            "Epoch 72/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1460 - accuracy: 0.9527\n",
            "Epoch 73/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1524 - accuracy: 0.9510\n",
            "Epoch 74/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1379 - accuracy: 0.9551\n",
            "Epoch 75/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1465 - accuracy: 0.9516\n",
            "Epoch 76/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1381 - accuracy: 0.9545\n",
            "Epoch 77/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1347 - accuracy: 0.9568\n",
            "Epoch 78/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1398 - accuracy: 0.9541\n",
            "Epoch 79/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1383 - accuracy: 0.9539\n",
            "Epoch 80/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1310 - accuracy: 0.9571\n",
            "Epoch 81/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1343 - accuracy: 0.9553\n",
            "Epoch 82/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1363 - accuracy: 0.9557\n",
            "Epoch 83/100\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 0.1329 - accuracy: 0.9566\n",
            "Epoch 84/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1291 - accuracy: 0.9569\n",
            "Epoch 85/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1341 - accuracy: 0.9545\n",
            "Epoch 86/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1210 - accuracy: 0.9609\n",
            "Epoch 87/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1212 - accuracy: 0.9594\n",
            "Epoch 88/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1230 - accuracy: 0.9589\n",
            "Epoch 89/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1261 - accuracy: 0.9575\n",
            "Epoch 90/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1183 - accuracy: 0.9607\n",
            "Epoch 91/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1283 - accuracy: 0.9566\n",
            "Epoch 92/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1136 - accuracy: 0.9619\n",
            "Epoch 93/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1190 - accuracy: 0.9606\n",
            "Epoch 94/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1237 - accuracy: 0.9598\n",
            "Epoch 95/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1242 - accuracy: 0.9581\n",
            "Epoch 96/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1230 - accuracy: 0.9594\n",
            "Epoch 97/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1169 - accuracy: 0.9610\n",
            "Epoch 98/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1154 - accuracy: 0.9618\n",
            "Epoch 99/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1198 - accuracy: 0.9597\n",
            "Epoch 100/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1151 - accuracy: 0.9628\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqPYCseYKRy_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "de5caa09-eef4-4825-d716-a3e7c68ecdca"
      },
      "source": [
        "results = model.evaluate(X_val, y_val)\n",
        "print('Val_acc using NN ADAM (Batch Normalization) : ', results[1])"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2905 - accuracy: 0.9395\n",
            "Val_acc using NN ADAM (Batch Normalization) :  0.9394999742507935\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28_uhtXDxoZP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "93a5ef34-ed9a-4ede-bc68-78f28cc78252"
      },
      "source": [
        "#Store the accuracy results for each model in a dataframe for final comparison\n",
        "tempResultsDf = pd.DataFrame({'Method':['NN ADAM (Batch Normalization)'], 'accuracy': [results[1]]},index={'3'})\n",
        "results_on_val= pd.concat([results_on_val, tempResultsDf])\n",
        "results_on_val = results_on_val[['Method', 'accuracy']]\n",
        "results_on_val"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Method</th>\n",
              "      <th>accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NN SDG</td>\n",
              "      <td>0.756950</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NN SGD (Batch Normalization)</td>\n",
              "      <td>0.756967</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NN ADAM (Batch Normalization)</td>\n",
              "      <td>0.939500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                          Method  accuracy\n",
              "1                         NN SDG  0.756950\n",
              "2   NN SGD (Batch Normalization)  0.756967\n",
              "3  NN ADAM (Batch Normalization)  0.939500"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vfQJ95mueTw",
        "colab_type": "text"
      },
      "source": [
        "## Hyper parameter tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1KVsbcFunHz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Create Model\n",
        "def train_and_test_loop(ir, lr, Lambda, verb=True):\n",
        "\n",
        "    ## hyperparameters\n",
        "    iterations = ir\n",
        "    learning_rate = lr\n",
        "    hidden_nodes = 128\n",
        "    output_nodes = 10\n",
        "\n",
        "    model = Sequential()\n",
        "    \n",
        "    model.add(Dense(hidden_nodes, input_shape = (1024, ), kernel_initializer='he_normal'))     # use he_normal initializer\n",
        "    model.add(BatchNormalization()) \n",
        "    model.add(Activation('relu'))    \n",
        "    model.add(Dense(hidden_nodes, kernel_initializer='he_normal'))                            # use he_normal initializer\n",
        "    model.add(BatchNormalization()) \n",
        "    model.add(Activation('relu'))    \n",
        "    model.add(Dense(output_nodes, kernel_initializer='he_normal'))                            # use he_normal initializer\n",
        "    model.add(Activation('softmax'))\n",
        "    \n",
        "    # Compile model\n",
        "    adam = optimizers.Adam(lr=learning_rate, decay=1e-6)\n",
        "    model.compile(optimizer = adam, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "    \n",
        "    # Fit the model\n",
        "    model.fit(X_train, y_train, epochs=iterations, batch_size=200, verbose= 1)\n",
        "    score = model.evaluate(X_val, y_val)\n",
        "    \n",
        "    return score"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F34SKaOX4F3P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "30cd5454-3d06-4865-9849-6cedc53050bf"
      },
      "source": [
        "import math\n",
        "for k in range(1,5):\n",
        "    ir = 100\n",
        "    lr = math.pow(10, np.random.uniform(-4.0, -2.0))\n",
        "    Lambda = math.pow(10, np.random.uniform(-6,-4))\n",
        "    best_acc = train_and_test_loop(ir, lr, Lambda, False)\n",
        "    print(\"Try {0}/{1}: Best_Training_acc: {2}, lr: {3}, Lambda: {4}\\n\".format(k, ir, best_acc, lr, Lambda))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 2.0664 - accuracy: 0.2912\n",
            "Epoch 2/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 1.4984 - accuracy: 0.5589\n",
            "Epoch 3/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 1.2287 - accuracy: 0.6572\n",
            "Epoch 4/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 1.0775 - accuracy: 0.6959\n",
            "Epoch 5/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.9769 - accuracy: 0.7229\n",
            "Epoch 6/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.9051 - accuracy: 0.7415\n",
            "Epoch 7/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.8475 - accuracy: 0.7559\n",
            "Epoch 8/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.7974 - accuracy: 0.7674\n",
            "Epoch 9/100\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 0.7576 - accuracy: 0.7776\n",
            "Epoch 10/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.7203 - accuracy: 0.7876\n",
            "Epoch 11/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.6858 - accuracy: 0.7985\n",
            "Epoch 12/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.6590 - accuracy: 0.8038\n",
            "Epoch 13/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.6358 - accuracy: 0.8110\n",
            "Epoch 14/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.6116 - accuracy: 0.8178\n",
            "Epoch 15/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.5904 - accuracy: 0.8242\n",
            "Epoch 16/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.5732 - accuracy: 0.8296\n",
            "Epoch 17/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.5570 - accuracy: 0.8330\n",
            "Epoch 18/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.5443 - accuracy: 0.8355\n",
            "Epoch 19/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.5278 - accuracy: 0.8413\n",
            "Epoch 20/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.5163 - accuracy: 0.8449\n",
            "Epoch 21/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.5040 - accuracy: 0.8489\n",
            "Epoch 22/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.4913 - accuracy: 0.8506\n",
            "Epoch 23/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.4814 - accuracy: 0.8545\n",
            "Epoch 24/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.4740 - accuracy: 0.8564\n",
            "Epoch 25/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.4630 - accuracy: 0.8609\n",
            "Epoch 26/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.4515 - accuracy: 0.8649\n",
            "Epoch 27/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.4424 - accuracy: 0.8656\n",
            "Epoch 28/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.4392 - accuracy: 0.8660\n",
            "Epoch 29/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.4267 - accuracy: 0.8718\n",
            "Epoch 30/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.4245 - accuracy: 0.8703\n",
            "Epoch 31/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.4134 - accuracy: 0.8745\n",
            "Epoch 32/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.4090 - accuracy: 0.8774\n",
            "Epoch 33/100\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 0.4013 - accuracy: 0.8788\n",
            "Epoch 34/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3979 - accuracy: 0.8798\n",
            "Epoch 35/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3904 - accuracy: 0.8815\n",
            "Epoch 36/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3848 - accuracy: 0.8827\n",
            "Epoch 37/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3804 - accuracy: 0.8848\n",
            "Epoch 38/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3750 - accuracy: 0.8869\n",
            "Epoch 39/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3714 - accuracy: 0.8874\n",
            "Epoch 40/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3666 - accuracy: 0.8883\n",
            "Epoch 41/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3611 - accuracy: 0.8892\n",
            "Epoch 42/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3542 - accuracy: 0.8923\n",
            "Epoch 43/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3493 - accuracy: 0.8938\n",
            "Epoch 44/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3423 - accuracy: 0.8953\n",
            "Epoch 45/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3419 - accuracy: 0.8956\n",
            "Epoch 46/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3386 - accuracy: 0.8970\n",
            "Epoch 47/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3350 - accuracy: 0.8976\n",
            "Epoch 48/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3280 - accuracy: 0.9005\n",
            "Epoch 49/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3285 - accuracy: 0.8992\n",
            "Epoch 50/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3291 - accuracy: 0.8981\n",
            "Epoch 51/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3198 - accuracy: 0.9015\n",
            "Epoch 52/100\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 0.3147 - accuracy: 0.9051\n",
            "Epoch 53/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3108 - accuracy: 0.9050\n",
            "Epoch 54/100\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 0.3105 - accuracy: 0.9051\n",
            "Epoch 55/100\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 0.3085 - accuracy: 0.9060\n",
            "Epoch 56/100\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 0.3004 - accuracy: 0.9090\n",
            "Epoch 57/100\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 0.2980 - accuracy: 0.9091\n",
            "Epoch 58/100\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 0.2946 - accuracy: 0.9092\n",
            "Epoch 59/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3018 - accuracy: 0.9079\n",
            "Epoch 60/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2953 - accuracy: 0.9103\n",
            "Epoch 61/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2864 - accuracy: 0.9119\n",
            "Epoch 62/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2880 - accuracy: 0.9129\n",
            "Epoch 63/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2845 - accuracy: 0.9129\n",
            "Epoch 64/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2807 - accuracy: 0.9146\n",
            "Epoch 65/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2800 - accuracy: 0.9130\n",
            "Epoch 66/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2794 - accuracy: 0.9137\n",
            "Epoch 67/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2725 - accuracy: 0.9173\n",
            "Epoch 68/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2737 - accuracy: 0.9165\n",
            "Epoch 69/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2690 - accuracy: 0.9178\n",
            "Epoch 70/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2677 - accuracy: 0.9180\n",
            "Epoch 71/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2620 - accuracy: 0.9200\n",
            "Epoch 72/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2605 - accuracy: 0.9203\n",
            "Epoch 73/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2638 - accuracy: 0.9204\n",
            "Epoch 74/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2568 - accuracy: 0.9220\n",
            "Epoch 75/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2589 - accuracy: 0.9215\n",
            "Epoch 76/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2534 - accuracy: 0.9223\n",
            "Epoch 77/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2515 - accuracy: 0.9237\n",
            "Epoch 78/100\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 0.2508 - accuracy: 0.9244\n",
            "Epoch 79/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2483 - accuracy: 0.9255\n",
            "Epoch 80/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2454 - accuracy: 0.9246\n",
            "Epoch 81/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2454 - accuracy: 0.9259\n",
            "Epoch 82/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2411 - accuracy: 0.9268\n",
            "Epoch 83/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2379 - accuracy: 0.9282\n",
            "Epoch 84/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2386 - accuracy: 0.9271\n",
            "Epoch 85/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2340 - accuracy: 0.9279\n",
            "Epoch 86/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2379 - accuracy: 0.9269\n",
            "Epoch 87/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2375 - accuracy: 0.9276\n",
            "Epoch 88/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2288 - accuracy: 0.9307\n",
            "Epoch 89/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2312 - accuracy: 0.9292\n",
            "Epoch 90/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2283 - accuracy: 0.9299\n",
            "Epoch 91/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2242 - accuracy: 0.9338\n",
            "Epoch 92/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2201 - accuracy: 0.9332\n",
            "Epoch 93/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2251 - accuracy: 0.9310\n",
            "Epoch 94/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2194 - accuracy: 0.9331\n",
            "Epoch 95/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2198 - accuracy: 0.9322\n",
            "Epoch 96/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2213 - accuracy: 0.9333\n",
            "Epoch 97/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2201 - accuracy: 0.9328\n",
            "Epoch 98/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2101 - accuracy: 0.9367\n",
            "Epoch 99/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2139 - accuracy: 0.9352\n",
            "Epoch 100/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2141 - accuracy: 0.9347\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.3002 - accuracy: 0.9220\n",
            "Try 1/100: Best_Training_acc: [0.3001948595046997, 0.9219833612442017], lr: 0.00011531761485516592, Lambda: 1.3514691856290533e-05\n",
            "\n",
            "Epoch 1/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 2.0327 - accuracy: 0.3083\n",
            "Epoch 2/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 1.4732 - accuracy: 0.5729\n",
            "Epoch 3/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 1.2087 - accuracy: 0.6644\n",
            "Epoch 4/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 1.0612 - accuracy: 0.7044\n",
            "Epoch 5/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.9576 - accuracy: 0.7299\n",
            "Epoch 6/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.8859 - accuracy: 0.7471\n",
            "Epoch 7/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.8235 - accuracy: 0.7623\n",
            "Epoch 8/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.7750 - accuracy: 0.7770\n",
            "Epoch 9/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.7319 - accuracy: 0.7865\n",
            "Epoch 10/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.6935 - accuracy: 0.7973\n",
            "Epoch 11/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.6656 - accuracy: 0.8048\n",
            "Epoch 12/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.6379 - accuracy: 0.8130\n",
            "Epoch 13/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.6124 - accuracy: 0.8205\n",
            "Epoch 14/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.5884 - accuracy: 0.8267\n",
            "Epoch 15/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.5727 - accuracy: 0.8305\n",
            "Epoch 16/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.5527 - accuracy: 0.8350\n",
            "Epoch 17/100\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 0.5426 - accuracy: 0.8397\n",
            "Epoch 18/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.5253 - accuracy: 0.8426\n",
            "Epoch 19/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.5130 - accuracy: 0.8451\n",
            "Epoch 20/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.5025 - accuracy: 0.8495\n",
            "Epoch 21/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.4892 - accuracy: 0.8544\n",
            "Epoch 22/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.4793 - accuracy: 0.8542\n",
            "Epoch 23/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.4713 - accuracy: 0.8592\n",
            "Epoch 24/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.4605 - accuracy: 0.8610\n",
            "Epoch 25/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.4511 - accuracy: 0.8638\n",
            "Epoch 26/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.4411 - accuracy: 0.8680\n",
            "Epoch 27/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.4359 - accuracy: 0.8677\n",
            "Epoch 28/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.4295 - accuracy: 0.8701\n",
            "Epoch 29/100\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 0.4198 - accuracy: 0.8726\n",
            "Epoch 30/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.4135 - accuracy: 0.8744\n",
            "Epoch 31/100\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 0.4067 - accuracy: 0.8766\n",
            "Epoch 32/100\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 0.4020 - accuracy: 0.8786\n",
            "Epoch 33/100\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 0.3963 - accuracy: 0.8793\n",
            "Epoch 34/100\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 0.3914 - accuracy: 0.8814\n",
            "Epoch 35/100\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 0.3846 - accuracy: 0.8834\n",
            "Epoch 36/100\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 0.3799 - accuracy: 0.8858\n",
            "Epoch 37/100\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 0.3749 - accuracy: 0.8872\n",
            "Epoch 38/100\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 0.3717 - accuracy: 0.8886\n",
            "Epoch 39/100\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 0.3633 - accuracy: 0.8905\n",
            "Epoch 40/100\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 0.3610 - accuracy: 0.8900\n",
            "Epoch 41/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3551 - accuracy: 0.8934\n",
            "Epoch 42/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3514 - accuracy: 0.8946\n",
            "Epoch 43/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3508 - accuracy: 0.8929\n",
            "Epoch 44/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3482 - accuracy: 0.8944\n",
            "Epoch 45/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3399 - accuracy: 0.8963\n",
            "Epoch 46/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3324 - accuracy: 0.8996\n",
            "Epoch 47/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3333 - accuracy: 0.8992\n",
            "Epoch 48/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3244 - accuracy: 0.9020\n",
            "Epoch 49/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3242 - accuracy: 0.9031\n",
            "Epoch 50/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3184 - accuracy: 0.9032\n",
            "Epoch 51/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3210 - accuracy: 0.9032\n",
            "Epoch 52/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3144 - accuracy: 0.9040\n",
            "Epoch 53/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3116 - accuracy: 0.9062\n",
            "Epoch 54/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3109 - accuracy: 0.9064\n",
            "Epoch 55/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3036 - accuracy: 0.9089\n",
            "Epoch 56/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3038 - accuracy: 0.9078\n",
            "Epoch 57/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3012 - accuracy: 0.9088\n",
            "Epoch 58/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2999 - accuracy: 0.9095\n",
            "Epoch 59/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2918 - accuracy: 0.9103\n",
            "Epoch 60/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2955 - accuracy: 0.9101\n",
            "Epoch 61/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2916 - accuracy: 0.9117\n",
            "Epoch 62/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2842 - accuracy: 0.9131\n",
            "Epoch 63/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2848 - accuracy: 0.9149\n",
            "Epoch 64/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2781 - accuracy: 0.9152\n",
            "Epoch 65/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2758 - accuracy: 0.9167\n",
            "Epoch 66/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2731 - accuracy: 0.9170\n",
            "Epoch 67/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2724 - accuracy: 0.9188\n",
            "Epoch 68/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2693 - accuracy: 0.9192\n",
            "Epoch 69/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2662 - accuracy: 0.9196\n",
            "Epoch 70/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2647 - accuracy: 0.9205\n",
            "Epoch 71/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2601 - accuracy: 0.9215\n",
            "Epoch 72/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2624 - accuracy: 0.9206\n",
            "Epoch 73/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2617 - accuracy: 0.9209\n",
            "Epoch 74/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2560 - accuracy: 0.9233\n",
            "Epoch 75/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2508 - accuracy: 0.9249\n",
            "Epoch 76/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2496 - accuracy: 0.9245\n",
            "Epoch 77/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2586 - accuracy: 0.9209\n",
            "Epoch 78/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2511 - accuracy: 0.9250\n",
            "Epoch 79/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2472 - accuracy: 0.9244\n",
            "Epoch 80/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2429 - accuracy: 0.9270\n",
            "Epoch 81/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2395 - accuracy: 0.9274\n",
            "Epoch 82/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2403 - accuracy: 0.9270\n",
            "Epoch 83/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2422 - accuracy: 0.9272\n",
            "Epoch 84/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2391 - accuracy: 0.9280\n",
            "Epoch 85/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2363 - accuracy: 0.9287\n",
            "Epoch 86/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2353 - accuracy: 0.9287\n",
            "Epoch 87/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2260 - accuracy: 0.9322\n",
            "Epoch 88/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2366 - accuracy: 0.9275\n",
            "Epoch 89/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2311 - accuracy: 0.9299\n",
            "Epoch 90/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2255 - accuracy: 0.9326\n",
            "Epoch 91/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2235 - accuracy: 0.9321\n",
            "Epoch 92/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2256 - accuracy: 0.9316\n",
            "Epoch 93/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2234 - accuracy: 0.9323\n",
            "Epoch 94/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2188 - accuracy: 0.9340\n",
            "Epoch 95/100\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 0.2189 - accuracy: 0.9340\n",
            "Epoch 96/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2158 - accuracy: 0.9346\n",
            "Epoch 97/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2176 - accuracy: 0.9340\n",
            "Epoch 98/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2106 - accuracy: 0.9367\n",
            "Epoch 99/100\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 0.2077 - accuracy: 0.9375\n",
            "Epoch 100/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2081 - accuracy: 0.9380\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2887 - accuracy: 0.9244\n",
            "Try 2/100: Best_Training_acc: [0.2887425422668457, 0.9244166612625122], lr: 0.000115770129038501, Lambda: 4.702154169856192e-06\n",
            "\n",
            "Epoch 1/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 1.9501 - accuracy: 0.3612\n",
            "Epoch 2/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 1.2709 - accuracy: 0.6417\n",
            "Epoch 3/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 1.0425 - accuracy: 0.7027\n",
            "Epoch 4/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.9203 - accuracy: 0.7334\n",
            "Epoch 5/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.8354 - accuracy: 0.7540\n",
            "Epoch 6/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.7650 - accuracy: 0.7743\n",
            "Epoch 7/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.7079 - accuracy: 0.7899\n",
            "Epoch 8/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.6686 - accuracy: 0.8005\n",
            "Epoch 9/100\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 0.6335 - accuracy: 0.8113\n",
            "Epoch 10/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.6032 - accuracy: 0.8194\n",
            "Epoch 11/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.5753 - accuracy: 0.8275\n",
            "Epoch 12/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.5535 - accuracy: 0.8329\n",
            "Epoch 13/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.5343 - accuracy: 0.8389\n",
            "Epoch 14/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.5171 - accuracy: 0.8439\n",
            "Epoch 15/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.5016 - accuracy: 0.8485\n",
            "Epoch 16/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.4870 - accuracy: 0.8520\n",
            "Epoch 17/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.4742 - accuracy: 0.8545\n",
            "Epoch 18/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.4608 - accuracy: 0.8607\n",
            "Epoch 19/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.4524 - accuracy: 0.8625\n",
            "Epoch 20/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.4421 - accuracy: 0.8659\n",
            "Epoch 21/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.4304 - accuracy: 0.8699\n",
            "Epoch 22/100\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 0.4203 - accuracy: 0.8721\n",
            "Epoch 23/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.4152 - accuracy: 0.8722\n",
            "Epoch 24/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.4064 - accuracy: 0.8746\n",
            "Epoch 25/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3984 - accuracy: 0.8773\n",
            "Epoch 26/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3911 - accuracy: 0.8793\n",
            "Epoch 27/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3801 - accuracy: 0.8836\n",
            "Epoch 28/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3781 - accuracy: 0.8833\n",
            "Epoch 29/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3655 - accuracy: 0.8876\n",
            "Epoch 30/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3627 - accuracy: 0.8880\n",
            "Epoch 31/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3565 - accuracy: 0.8930\n",
            "Epoch 32/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3519 - accuracy: 0.8911\n",
            "Epoch 33/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3451 - accuracy: 0.8941\n",
            "Epoch 34/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3403 - accuracy: 0.8957\n",
            "Epoch 35/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3357 - accuracy: 0.8966\n",
            "Epoch 36/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3321 - accuracy: 0.8981\n",
            "Epoch 37/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3237 - accuracy: 0.9015\n",
            "Epoch 38/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3258 - accuracy: 0.8996\n",
            "Epoch 39/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3173 - accuracy: 0.9035\n",
            "Epoch 40/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3137 - accuracy: 0.9035\n",
            "Epoch 41/100\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 0.3140 - accuracy: 0.9047\n",
            "Epoch 42/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3069 - accuracy: 0.9060\n",
            "Epoch 43/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3022 - accuracy: 0.9075\n",
            "Epoch 44/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2988 - accuracy: 0.9083\n",
            "Epoch 45/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2922 - accuracy: 0.9121\n",
            "Epoch 46/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2911 - accuracy: 0.9111\n",
            "Epoch 47/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2875 - accuracy: 0.9120\n",
            "Epoch 48/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2880 - accuracy: 0.9114\n",
            "Epoch 49/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2823 - accuracy: 0.9133\n",
            "Epoch 50/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2774 - accuracy: 0.9156\n",
            "Epoch 51/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2740 - accuracy: 0.9170\n",
            "Epoch 52/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2650 - accuracy: 0.9190\n",
            "Epoch 53/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2692 - accuracy: 0.9184\n",
            "Epoch 54/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2615 - accuracy: 0.9196\n",
            "Epoch 55/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2639 - accuracy: 0.9198\n",
            "Epoch 56/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2586 - accuracy: 0.9213\n",
            "Epoch 57/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2601 - accuracy: 0.9209\n",
            "Epoch 58/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2555 - accuracy: 0.9222\n",
            "Epoch 59/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2537 - accuracy: 0.9206\n",
            "Epoch 60/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2584 - accuracy: 0.9206\n",
            "Epoch 61/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2436 - accuracy: 0.9253\n",
            "Epoch 62/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2455 - accuracy: 0.9251\n",
            "Epoch 63/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2422 - accuracy: 0.9264\n",
            "Epoch 64/100\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 0.2411 - accuracy: 0.9265\n",
            "Epoch 65/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2368 - accuracy: 0.9267\n",
            "Epoch 66/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2321 - accuracy: 0.9292\n",
            "Epoch 67/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2341 - accuracy: 0.9275\n",
            "Epoch 68/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2308 - accuracy: 0.9287\n",
            "Epoch 69/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2260 - accuracy: 0.9307\n",
            "Epoch 70/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2323 - accuracy: 0.9290\n",
            "Epoch 71/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2242 - accuracy: 0.9308\n",
            "Epoch 72/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2224 - accuracy: 0.9326\n",
            "Epoch 73/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2238 - accuracy: 0.9312\n",
            "Epoch 74/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2263 - accuracy: 0.9307\n",
            "Epoch 75/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2099 - accuracy: 0.9358\n",
            "Epoch 76/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2126 - accuracy: 0.9353\n",
            "Epoch 77/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2156 - accuracy: 0.9329\n",
            "Epoch 78/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2092 - accuracy: 0.9361\n",
            "Epoch 79/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2076 - accuracy: 0.9359\n",
            "Epoch 80/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2090 - accuracy: 0.9354\n",
            "Epoch 81/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2025 - accuracy: 0.9380\n",
            "Epoch 82/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2043 - accuracy: 0.9374\n",
            "Epoch 83/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1996 - accuracy: 0.9391\n",
            "Epoch 84/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1971 - accuracy: 0.9386\n",
            "Epoch 85/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2007 - accuracy: 0.9385\n",
            "Epoch 86/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2017 - accuracy: 0.9384\n",
            "Epoch 87/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1959 - accuracy: 0.9404\n",
            "Epoch 88/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1981 - accuracy: 0.9387\n",
            "Epoch 89/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1917 - accuracy: 0.9411\n",
            "Epoch 90/100\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 0.1892 - accuracy: 0.9417\n",
            "Epoch 91/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1850 - accuracy: 0.9431\n",
            "Epoch 92/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1881 - accuracy: 0.9430\n",
            "Epoch 93/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1871 - accuracy: 0.9429\n",
            "Epoch 94/100\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 0.1823 - accuracy: 0.9454\n",
            "Epoch 95/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1839 - accuracy: 0.9425\n",
            "Epoch 96/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1769 - accuracy: 0.9470\n",
            "Epoch 97/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1743 - accuracy: 0.9469\n",
            "Epoch 98/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1769 - accuracy: 0.9463\n",
            "Epoch 99/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1726 - accuracy: 0.9473\n",
            "Epoch 100/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1787 - accuracy: 0.9451\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2819 - accuracy: 0.9284\n",
            "Try 3/100: Best_Training_acc: [0.28189074993133545, 0.9284499883651733], lr: 0.0001881508510636344, Lambda: 1.8326999810821896e-05\n",
            "\n",
            "Epoch 1/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 1.4105 - accuracy: 0.5523\n",
            "Epoch 2/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.9033 - accuracy: 0.7212\n",
            "Epoch 3/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.7599 - accuracy: 0.7657\n",
            "Epoch 4/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.6785 - accuracy: 0.7917\n",
            "Epoch 5/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.6216 - accuracy: 0.8100\n",
            "Epoch 6/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.5806 - accuracy: 0.8213\n",
            "Epoch 7/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.5415 - accuracy: 0.8327\n",
            "Epoch 8/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.5243 - accuracy: 0.8382\n",
            "Epoch 9/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.4891 - accuracy: 0.8493\n",
            "Epoch 10/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.4772 - accuracy: 0.8528\n",
            "Epoch 11/100\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 0.4565 - accuracy: 0.8590\n",
            "Epoch 12/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.4359 - accuracy: 0.8641\n",
            "Epoch 13/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.4209 - accuracy: 0.8698\n",
            "Epoch 14/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.4067 - accuracy: 0.8731\n",
            "Epoch 15/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.4000 - accuracy: 0.8742\n",
            "Epoch 16/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3798 - accuracy: 0.8825\n",
            "Epoch 17/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3823 - accuracy: 0.8790\n",
            "Epoch 18/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3585 - accuracy: 0.8865\n",
            "Epoch 19/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3464 - accuracy: 0.8912\n",
            "Epoch 20/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3531 - accuracy: 0.8892\n",
            "Epoch 21/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3318 - accuracy: 0.8960\n",
            "Epoch 22/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3239 - accuracy: 0.8970\n",
            "Epoch 23/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3163 - accuracy: 0.9003\n",
            "Epoch 24/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3037 - accuracy: 0.9037\n",
            "Epoch 25/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3049 - accuracy: 0.9039\n",
            "Epoch 26/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2975 - accuracy: 0.9056\n",
            "Epoch 27/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2841 - accuracy: 0.9099\n",
            "Epoch 28/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2902 - accuracy: 0.9078\n",
            "Epoch 29/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2723 - accuracy: 0.9140\n",
            "Epoch 30/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2698 - accuracy: 0.9141\n",
            "Epoch 31/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2638 - accuracy: 0.9163\n",
            "Epoch 32/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2613 - accuracy: 0.9155\n",
            "Epoch 33/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2586 - accuracy: 0.9167\n",
            "Epoch 34/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2461 - accuracy: 0.9217\n",
            "Epoch 35/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2494 - accuracy: 0.9204\n",
            "Epoch 36/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2436 - accuracy: 0.9216\n",
            "Epoch 37/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2317 - accuracy: 0.9249\n",
            "Epoch 38/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2304 - accuracy: 0.9263\n",
            "Epoch 39/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2251 - accuracy: 0.9267\n",
            "Epoch 40/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2281 - accuracy: 0.9252\n",
            "Epoch 41/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2187 - accuracy: 0.9295\n",
            "Epoch 42/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2144 - accuracy: 0.9298\n",
            "Epoch 43/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2142 - accuracy: 0.9309\n",
            "Epoch 44/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2073 - accuracy: 0.9332\n",
            "Epoch 45/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2062 - accuracy: 0.9332\n",
            "Epoch 46/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1972 - accuracy: 0.9347\n",
            "Epoch 47/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1916 - accuracy: 0.9376\n",
            "Epoch 48/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2043 - accuracy: 0.9328\n",
            "Epoch 49/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1992 - accuracy: 0.9346\n",
            "Epoch 50/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1883 - accuracy: 0.9377\n",
            "Epoch 51/100\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 0.1786 - accuracy: 0.9423\n",
            "Epoch 52/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1927 - accuracy: 0.9372\n",
            "Epoch 53/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1845 - accuracy: 0.9399\n",
            "Epoch 54/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1790 - accuracy: 0.9406\n",
            "Epoch 55/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1789 - accuracy: 0.9406\n",
            "Epoch 56/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1761 - accuracy: 0.9409\n",
            "Epoch 57/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1628 - accuracy: 0.9451\n",
            "Epoch 58/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1762 - accuracy: 0.9411\n",
            "Epoch 59/100\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 0.1664 - accuracy: 0.9454\n",
            "Epoch 60/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1623 - accuracy: 0.9468\n",
            "Epoch 61/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1621 - accuracy: 0.9461\n",
            "Epoch 62/100\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 0.1590 - accuracy: 0.9477\n",
            "Epoch 63/100\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 0.1568 - accuracy: 0.9481\n",
            "Epoch 64/100\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 0.1590 - accuracy: 0.9481\n",
            "Epoch 65/100\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 0.1554 - accuracy: 0.9494\n",
            "Epoch 66/100\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 0.1622 - accuracy: 0.9455\n",
            "Epoch 67/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1540 - accuracy: 0.9481\n",
            "Epoch 68/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1550 - accuracy: 0.9475\n",
            "Epoch 69/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1589 - accuracy: 0.9464\n",
            "Epoch 70/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1395 - accuracy: 0.9527\n",
            "Epoch 71/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1479 - accuracy: 0.9506\n",
            "Epoch 72/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1400 - accuracy: 0.9536\n",
            "Epoch 73/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1437 - accuracy: 0.9517\n",
            "Epoch 74/100\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 0.1369 - accuracy: 0.9541\n",
            "Epoch 75/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1379 - accuracy: 0.9540\n",
            "Epoch 76/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1378 - accuracy: 0.9527\n",
            "Epoch 77/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1341 - accuracy: 0.9552\n",
            "Epoch 78/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1401 - accuracy: 0.9528\n",
            "Epoch 79/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1356 - accuracy: 0.9541\n",
            "Epoch 80/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1280 - accuracy: 0.9574\n",
            "Epoch 81/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1256 - accuracy: 0.9571\n",
            "Epoch 82/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1224 - accuracy: 0.9592\n",
            "Epoch 83/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1306 - accuracy: 0.9556\n",
            "Epoch 84/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1278 - accuracy: 0.9566\n",
            "Epoch 85/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1218 - accuracy: 0.9578\n",
            "Epoch 86/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1156 - accuracy: 0.9615\n",
            "Epoch 87/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1280 - accuracy: 0.9575\n",
            "Epoch 88/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1242 - accuracy: 0.9578\n",
            "Epoch 89/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1200 - accuracy: 0.9596\n",
            "Epoch 90/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1180 - accuracy: 0.9599\n",
            "Epoch 91/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1233 - accuracy: 0.9581\n",
            "Epoch 92/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1155 - accuracy: 0.9600\n",
            "Epoch 93/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1079 - accuracy: 0.9640\n",
            "Epoch 94/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1061 - accuracy: 0.9648\n",
            "Epoch 95/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1185 - accuracy: 0.9595\n",
            "Epoch 96/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1131 - accuracy: 0.9615\n",
            "Epoch 97/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1145 - accuracy: 0.9619\n",
            "Epoch 98/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1135 - accuracy: 0.9618\n",
            "Epoch 99/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1001 - accuracy: 0.9674\n",
            "Epoch 100/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1032 - accuracy: 0.9650\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3399 - accuracy: 0.9304\n",
            "Try 4/100: Best_Training_acc: [0.3398961126804352, 0.930400013923645], lr: 0.0013629078871557837, Lambda: 7.254795763233311e-06\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZn2KE6xH_lk",
        "colab_type": "text"
      },
      "source": [
        "As from above, Case 4 yields best accuracy when Learning rate = 0.0036 and Lamda = 1.29e-6"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsOT281UINLu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f77ea5c2-7818-495f-c802-c4a31763e5ed"
      },
      "source": [
        "import math\n",
        "for k in range(1,5):\n",
        "    ir=100\n",
        "    lr = math.pow(10, np.random.uniform(-4.0, -2.0))\n",
        "    Lambda = math.pow(10, np.random.uniform(-4,-2))\n",
        "    best_acc = train_and_test_loop(100, lr, Lambda, False)\n",
        "    print(\"Try {0}/{1}: Best_val_acc: {2}, lr: {3}, Lambda: {4}\\n\".format(k, ir, best_acc, lr, Lambda))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 2.1187 - accuracy: 0.2669\n",
            "Epoch 2/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 1.5392 - accuracy: 0.5411\n",
            "Epoch 3/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 1.2619 - accuracy: 0.6424\n",
            "Epoch 4/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 1.1037 - accuracy: 0.6905\n",
            "Epoch 5/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 1.0011 - accuracy: 0.7160\n",
            "Epoch 6/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.9263 - accuracy: 0.7349\n",
            "Epoch 7/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.8630 - accuracy: 0.7520\n",
            "Epoch 8/100\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 0.8145 - accuracy: 0.7648\n",
            "Epoch 9/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.7729 - accuracy: 0.7754\n",
            "Epoch 10/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.7341 - accuracy: 0.7859\n",
            "Epoch 11/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.7011 - accuracy: 0.7951\n",
            "Epoch 12/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.6764 - accuracy: 0.8014\n",
            "Epoch 13/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.6494 - accuracy: 0.8086\n",
            "Epoch 14/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.6243 - accuracy: 0.8153\n",
            "Epoch 15/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.6050 - accuracy: 0.8212\n",
            "Epoch 16/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.5867 - accuracy: 0.8247\n",
            "Epoch 17/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.5681 - accuracy: 0.8316\n",
            "Epoch 18/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.5544 - accuracy: 0.8348\n",
            "Epoch 19/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.5409 - accuracy: 0.8385\n",
            "Epoch 20/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.5238 - accuracy: 0.8436\n",
            "Epoch 21/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.5154 - accuracy: 0.8448\n",
            "Epoch 22/100\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 0.5026 - accuracy: 0.8506\n",
            "Epoch 23/100\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 0.4914 - accuracy: 0.8523\n",
            "Epoch 24/100\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 0.4787 - accuracy: 0.8565\n",
            "Epoch 25/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.4734 - accuracy: 0.8556\n",
            "Epoch 26/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.4630 - accuracy: 0.8597\n",
            "Epoch 27/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.4538 - accuracy: 0.8626\n",
            "Epoch 28/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.4476 - accuracy: 0.8650\n",
            "Epoch 29/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.4387 - accuracy: 0.8668\n",
            "Epoch 30/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.4352 - accuracy: 0.8680\n",
            "Epoch 31/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.4265 - accuracy: 0.8712\n",
            "Epoch 32/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.4215 - accuracy: 0.8730\n",
            "Epoch 33/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.4151 - accuracy: 0.8743\n",
            "Epoch 34/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.4059 - accuracy: 0.8770\n",
            "Epoch 35/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.4029 - accuracy: 0.8770\n",
            "Epoch 36/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3931 - accuracy: 0.8809\n",
            "Epoch 37/100\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 0.3876 - accuracy: 0.8817\n",
            "Epoch 38/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3843 - accuracy: 0.8823\n",
            "Epoch 39/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3799 - accuracy: 0.8834\n",
            "Epoch 40/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3735 - accuracy: 0.8860\n",
            "Epoch 41/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3672 - accuracy: 0.8882\n",
            "Epoch 42/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3626 - accuracy: 0.8890\n",
            "Epoch 43/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3622 - accuracy: 0.8902\n",
            "Epoch 44/100\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 0.3580 - accuracy: 0.8899\n",
            "Epoch 45/100\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 0.3552 - accuracy: 0.8920\n",
            "Epoch 46/100\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 0.3419 - accuracy: 0.8965\n",
            "Epoch 47/100\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 0.3457 - accuracy: 0.8938\n",
            "Epoch 48/100\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 0.3377 - accuracy: 0.8978\n",
            "Epoch 49/100\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 0.3408 - accuracy: 0.8945\n",
            "Epoch 50/100\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 0.3293 - accuracy: 0.9004\n",
            "Epoch 51/100\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 0.3304 - accuracy: 0.8992\n",
            "Epoch 52/100\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 0.3255 - accuracy: 0.9002\n",
            "Epoch 53/100\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 0.3217 - accuracy: 0.9020\n",
            "Epoch 54/100\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 0.3208 - accuracy: 0.9025\n",
            "Epoch 55/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3154 - accuracy: 0.9039\n",
            "Epoch 56/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3116 - accuracy: 0.9050\n",
            "Epoch 57/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3084 - accuracy: 0.9069\n",
            "Epoch 58/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3049 - accuracy: 0.9073\n",
            "Epoch 59/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3029 - accuracy: 0.9065\n",
            "Epoch 60/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2966 - accuracy: 0.9081\n",
            "Epoch 61/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2959 - accuracy: 0.9108\n",
            "Epoch 62/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2938 - accuracy: 0.9102\n",
            "Epoch 63/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2913 - accuracy: 0.9118\n",
            "Epoch 64/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2890 - accuracy: 0.9121\n",
            "Epoch 65/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2898 - accuracy: 0.9122\n",
            "Epoch 66/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2794 - accuracy: 0.9151\n",
            "Epoch 67/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2788 - accuracy: 0.9155\n",
            "Epoch 68/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2787 - accuracy: 0.9146\n",
            "Epoch 69/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2762 - accuracy: 0.9155\n",
            "Epoch 70/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2747 - accuracy: 0.9160\n",
            "Epoch 71/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2682 - accuracy: 0.9174\n",
            "Epoch 72/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2622 - accuracy: 0.9199\n",
            "Epoch 73/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2682 - accuracy: 0.9182\n",
            "Epoch 74/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2613 - accuracy: 0.9203\n",
            "Epoch 75/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2629 - accuracy: 0.9205\n",
            "Epoch 76/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2613 - accuracy: 0.9211\n",
            "Epoch 77/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2530 - accuracy: 0.9243\n",
            "Epoch 78/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2533 - accuracy: 0.9228\n",
            "Epoch 79/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2560 - accuracy: 0.9218\n",
            "Epoch 80/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2548 - accuracy: 0.9210\n",
            "Epoch 81/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2496 - accuracy: 0.9250\n",
            "Epoch 82/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2435 - accuracy: 0.9265\n",
            "Epoch 83/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2458 - accuracy: 0.9250\n",
            "Epoch 84/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2415 - accuracy: 0.9258\n",
            "Epoch 85/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2353 - accuracy: 0.9283\n",
            "Epoch 86/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2419 - accuracy: 0.9258\n",
            "Epoch 87/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2368 - accuracy: 0.9278\n",
            "Epoch 88/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2393 - accuracy: 0.9269\n",
            "Epoch 89/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2351 - accuracy: 0.9291\n",
            "Epoch 90/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2331 - accuracy: 0.9289\n",
            "Epoch 91/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2297 - accuracy: 0.9307\n",
            "Epoch 92/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2272 - accuracy: 0.9308\n",
            "Epoch 93/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2260 - accuracy: 0.9317\n",
            "Epoch 94/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2222 - accuracy: 0.9339\n",
            "Epoch 95/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2236 - accuracy: 0.9323\n",
            "Epoch 96/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2193 - accuracy: 0.9339\n",
            "Epoch 97/100\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 0.2208 - accuracy: 0.9331\n",
            "Epoch 98/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2188 - accuracy: 0.9330\n",
            "Epoch 99/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2144 - accuracy: 0.9348\n",
            "Epoch 100/100\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 0.2145 - accuracy: 0.9350\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.2940 - accuracy: 0.9220\n",
            "Try 1/100: Best_val_acc: [0.2940332591533661, 0.9219833612442017], lr: 0.00011110443474374488, Lambda: 0.0005774905689327037\n",
            "\n",
            "Epoch 1/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 1.3973 - accuracy: 0.5355\n",
            "Epoch 2/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.8855 - accuracy: 0.7227\n",
            "Epoch 3/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.7500 - accuracy: 0.7676\n",
            "Epoch 4/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.6739 - accuracy: 0.7911\n",
            "Epoch 5/100\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 0.6136 - accuracy: 0.8106\n",
            "Epoch 6/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.5800 - accuracy: 0.8195\n",
            "Epoch 7/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.5416 - accuracy: 0.8309\n",
            "Epoch 8/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.5205 - accuracy: 0.8370\n",
            "Epoch 9/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.4931 - accuracy: 0.8462\n",
            "Epoch 10/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.4745 - accuracy: 0.8509\n",
            "Epoch 11/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.4609 - accuracy: 0.8540\n",
            "Epoch 12/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.4358 - accuracy: 0.8629\n",
            "Epoch 13/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.4285 - accuracy: 0.8646\n",
            "Epoch 14/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.4090 - accuracy: 0.8697\n",
            "Epoch 15/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3989 - accuracy: 0.8730\n",
            "Epoch 16/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3894 - accuracy: 0.8780\n",
            "Epoch 17/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3836 - accuracy: 0.8784\n",
            "Epoch 18/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3685 - accuracy: 0.8820\n",
            "Epoch 19/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3658 - accuracy: 0.8821\n",
            "Epoch 20/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3491 - accuracy: 0.8880\n",
            "Epoch 21/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3384 - accuracy: 0.8914\n",
            "Epoch 22/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3290 - accuracy: 0.8946\n",
            "Epoch 23/100\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 0.3245 - accuracy: 0.8939\n",
            "Epoch 24/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3083 - accuracy: 0.8985\n",
            "Epoch 25/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3167 - accuracy: 0.8984\n",
            "Epoch 26/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2967 - accuracy: 0.9035\n",
            "Epoch 27/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2869 - accuracy: 0.9065\n",
            "Epoch 28/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2917 - accuracy: 0.9055\n",
            "Epoch 29/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2777 - accuracy: 0.9097\n",
            "Epoch 30/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2749 - accuracy: 0.9105\n",
            "Epoch 31/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2744 - accuracy: 0.9088\n",
            "Epoch 32/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2628 - accuracy: 0.9139\n",
            "Epoch 33/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2546 - accuracy: 0.9179\n",
            "Epoch 34/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2555 - accuracy: 0.9158\n",
            "Epoch 35/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2469 - accuracy: 0.9184\n",
            "Epoch 36/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2488 - accuracy: 0.9173\n",
            "Epoch 37/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2378 - accuracy: 0.9214\n",
            "Epoch 38/100\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 0.2357 - accuracy: 0.9210\n",
            "Epoch 39/100\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 0.2262 - accuracy: 0.9259\n",
            "Epoch 40/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2211 - accuracy: 0.9263\n",
            "Epoch 41/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2323 - accuracy: 0.9232\n",
            "Epoch 42/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2157 - accuracy: 0.9281\n",
            "Epoch 43/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2220 - accuracy: 0.9251\n",
            "Epoch 44/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2124 - accuracy: 0.9293\n",
            "Epoch 45/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2138 - accuracy: 0.9280\n",
            "Epoch 46/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2089 - accuracy: 0.9302\n",
            "Epoch 47/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2057 - accuracy: 0.9305\n",
            "Epoch 48/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1997 - accuracy: 0.9335\n",
            "Epoch 49/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1960 - accuracy: 0.9344\n",
            "Epoch 50/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1929 - accuracy: 0.9354\n",
            "Epoch 51/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1916 - accuracy: 0.9350\n",
            "Epoch 52/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1839 - accuracy: 0.9378\n",
            "Epoch 53/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1865 - accuracy: 0.9375\n",
            "Epoch 54/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1799 - accuracy: 0.9392\n",
            "Epoch 55/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1788 - accuracy: 0.9389\n",
            "Epoch 56/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1819 - accuracy: 0.9383\n",
            "Epoch 57/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1785 - accuracy: 0.9389\n",
            "Epoch 58/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1770 - accuracy: 0.9388\n",
            "Epoch 59/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1720 - accuracy: 0.9424\n",
            "Epoch 60/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1713 - accuracy: 0.9426\n",
            "Epoch 61/100\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 0.1639 - accuracy: 0.9439\n",
            "Epoch 62/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1607 - accuracy: 0.9448\n",
            "Epoch 63/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1567 - accuracy: 0.9470\n",
            "Epoch 64/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1609 - accuracy: 0.9454\n",
            "Epoch 65/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1642 - accuracy: 0.9450\n",
            "Epoch 66/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1575 - accuracy: 0.9466\n",
            "Epoch 67/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1618 - accuracy: 0.9456\n",
            "Epoch 68/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1451 - accuracy: 0.9510\n",
            "Epoch 69/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1469 - accuracy: 0.9500\n",
            "Epoch 70/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1488 - accuracy: 0.9487\n",
            "Epoch 71/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1538 - accuracy: 0.9466\n",
            "Epoch 72/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1467 - accuracy: 0.9497\n",
            "Epoch 73/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1520 - accuracy: 0.9473\n",
            "Epoch 74/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1471 - accuracy: 0.9507\n",
            "Epoch 75/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1430 - accuracy: 0.9504\n",
            "Epoch 76/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1347 - accuracy: 0.9539\n",
            "Epoch 77/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1490 - accuracy: 0.9494\n",
            "Epoch 78/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1353 - accuracy: 0.9540\n",
            "Epoch 79/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1211 - accuracy: 0.9602\n",
            "Epoch 80/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1315 - accuracy: 0.9550\n",
            "Epoch 81/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1358 - accuracy: 0.9537\n",
            "Epoch 82/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1404 - accuracy: 0.9508\n",
            "Epoch 83/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1348 - accuracy: 0.9540\n",
            "Epoch 84/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1298 - accuracy: 0.9551\n",
            "Epoch 85/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1309 - accuracy: 0.9548\n",
            "Epoch 86/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1306 - accuracy: 0.9557\n",
            "Epoch 87/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1358 - accuracy: 0.9536\n",
            "Epoch 88/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1237 - accuracy: 0.9565\n",
            "Epoch 89/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1277 - accuracy: 0.9570\n",
            "Epoch 90/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1255 - accuracy: 0.9570\n",
            "Epoch 91/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1229 - accuracy: 0.9578\n",
            "Epoch 92/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1129 - accuracy: 0.9611\n",
            "Epoch 93/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1210 - accuracy: 0.9580\n",
            "Epoch 94/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1203 - accuracy: 0.9578\n",
            "Epoch 95/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1212 - accuracy: 0.9586\n",
            "Epoch 96/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1153 - accuracy: 0.9607\n",
            "Epoch 97/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1191 - accuracy: 0.9601\n",
            "Epoch 98/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1158 - accuracy: 0.9596\n",
            "Epoch 99/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1151 - accuracy: 0.9592\n",
            "Epoch 100/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1232 - accuracy: 0.9568\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3630 - accuracy: 0.9301\n",
            "Try 2/100: Best_val_acc: [0.3630351126194, 0.9300500154495239], lr: 0.006101938347948367, Lambda: 0.008816378811130848\n",
            "\n",
            "Epoch 1/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 1.6376 - accuracy: 0.4824\n",
            "Epoch 2/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 1.0106 - accuracy: 0.7060\n",
            "Epoch 3/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.8347 - accuracy: 0.7523\n",
            "Epoch 4/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.7399 - accuracy: 0.7784\n",
            "Epoch 5/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.6720 - accuracy: 0.7966\n",
            "Epoch 6/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.6215 - accuracy: 0.8131\n",
            "Epoch 7/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.5854 - accuracy: 0.8237\n",
            "Epoch 8/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.5506 - accuracy: 0.8330\n",
            "Epoch 9/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.5298 - accuracy: 0.8400\n",
            "Epoch 10/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.5087 - accuracy: 0.8441\n",
            "Epoch 11/100\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 0.4878 - accuracy: 0.8519\n",
            "Epoch 12/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.4689 - accuracy: 0.8564\n",
            "Epoch 13/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.4577 - accuracy: 0.8598\n",
            "Epoch 14/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.4464 - accuracy: 0.8619\n",
            "Epoch 15/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.4237 - accuracy: 0.8701\n",
            "Epoch 16/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.4133 - accuracy: 0.8733\n",
            "Epoch 17/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.4096 - accuracy: 0.8745\n",
            "Epoch 18/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.4040 - accuracy: 0.8758\n",
            "Epoch 19/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3932 - accuracy: 0.8772\n",
            "Epoch 20/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3761 - accuracy: 0.8841\n",
            "Epoch 21/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3757 - accuracy: 0.8831\n",
            "Epoch 22/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3703 - accuracy: 0.8845\n",
            "Epoch 23/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3491 - accuracy: 0.8922\n",
            "Epoch 24/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3438 - accuracy: 0.8944\n",
            "Epoch 25/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3394 - accuracy: 0.8946\n",
            "Epoch 26/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3363 - accuracy: 0.8944\n",
            "Epoch 27/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3239 - accuracy: 0.9002\n",
            "Epoch 28/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3190 - accuracy: 0.9012\n",
            "Epoch 29/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3184 - accuracy: 0.9006\n",
            "Epoch 30/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3087 - accuracy: 0.9050\n",
            "Epoch 31/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3000 - accuracy: 0.9070\n",
            "Epoch 32/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2978 - accuracy: 0.9077\n",
            "Epoch 33/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2962 - accuracy: 0.9073\n",
            "Epoch 34/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2903 - accuracy: 0.9090\n",
            "Epoch 35/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2872 - accuracy: 0.9100\n",
            "Epoch 36/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2788 - accuracy: 0.9135\n",
            "Epoch 37/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2741 - accuracy: 0.9165\n",
            "Epoch 38/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2693 - accuracy: 0.9161\n",
            "Epoch 39/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2706 - accuracy: 0.9167\n",
            "Epoch 40/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2648 - accuracy: 0.9173\n",
            "Epoch 41/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2614 - accuracy: 0.9191\n",
            "Epoch 42/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2612 - accuracy: 0.9172\n",
            "Epoch 43/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2472 - accuracy: 0.9229\n",
            "Epoch 44/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2456 - accuracy: 0.9233\n",
            "Epoch 45/100\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 0.2436 - accuracy: 0.9237\n",
            "Epoch 46/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2376 - accuracy: 0.9264\n",
            "Epoch 47/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2438 - accuracy: 0.9239\n",
            "Epoch 48/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2324 - accuracy: 0.9271\n",
            "Epoch 49/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2381 - accuracy: 0.9260\n",
            "Epoch 50/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2288 - accuracy: 0.9280\n",
            "Epoch 51/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2237 - accuracy: 0.9301\n",
            "Epoch 52/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2222 - accuracy: 0.9311\n",
            "Epoch 53/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2212 - accuracy: 0.9316\n",
            "Epoch 54/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2146 - accuracy: 0.9335\n",
            "Epoch 55/100\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 0.2109 - accuracy: 0.9342\n",
            "Epoch 56/100\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 0.2106 - accuracy: 0.9335\n",
            "Epoch 57/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2075 - accuracy: 0.9364\n",
            "Epoch 58/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2065 - accuracy: 0.9354\n",
            "Epoch 59/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2069 - accuracy: 0.9350\n",
            "Epoch 60/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2048 - accuracy: 0.9360\n",
            "Epoch 61/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1999 - accuracy: 0.9372\n",
            "Epoch 62/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1921 - accuracy: 0.9394\n",
            "Epoch 63/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1934 - accuracy: 0.9397\n",
            "Epoch 64/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1942 - accuracy: 0.9387\n",
            "Epoch 65/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1914 - accuracy: 0.9397\n",
            "Epoch 66/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1866 - accuracy: 0.9425\n",
            "Epoch 67/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1854 - accuracy: 0.9426\n",
            "Epoch 68/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1795 - accuracy: 0.9447\n",
            "Epoch 69/100\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 0.1838 - accuracy: 0.9424\n",
            "Epoch 70/100\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 0.1796 - accuracy: 0.9443\n",
            "Epoch 71/100\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 0.1783 - accuracy: 0.9437\n",
            "Epoch 72/100\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 0.1779 - accuracy: 0.9433\n",
            "Epoch 73/100\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 0.1733 - accuracy: 0.9454\n",
            "Epoch 74/100\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 0.1762 - accuracy: 0.9437\n",
            "Epoch 75/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1662 - accuracy: 0.9480\n",
            "Epoch 76/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1708 - accuracy: 0.9465\n",
            "Epoch 77/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1639 - accuracy: 0.9478\n",
            "Epoch 78/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1701 - accuracy: 0.9450\n",
            "Epoch 79/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1638 - accuracy: 0.9493\n",
            "Epoch 80/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1597 - accuracy: 0.9491\n",
            "Epoch 81/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1543 - accuracy: 0.9524\n",
            "Epoch 82/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1620 - accuracy: 0.9480\n",
            "Epoch 83/100\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 0.1577 - accuracy: 0.9504\n",
            "Epoch 84/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1504 - accuracy: 0.9532\n",
            "Epoch 85/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1550 - accuracy: 0.9512\n",
            "Epoch 86/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1547 - accuracy: 0.9497\n",
            "Epoch 87/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1478 - accuracy: 0.9528\n",
            "Epoch 88/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1507 - accuracy: 0.9516\n",
            "Epoch 89/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1426 - accuracy: 0.9555\n",
            "Epoch 90/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1484 - accuracy: 0.9531\n",
            "Epoch 91/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1440 - accuracy: 0.9539\n",
            "Epoch 92/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1460 - accuracy: 0.9537\n",
            "Epoch 93/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1406 - accuracy: 0.9552\n",
            "Epoch 94/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1431 - accuracy: 0.9544\n",
            "Epoch 95/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1369 - accuracy: 0.9565\n",
            "Epoch 96/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1387 - accuracy: 0.9554\n",
            "Epoch 97/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1389 - accuracy: 0.9549\n",
            "Epoch 98/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1396 - accuracy: 0.9568\n",
            "Epoch 99/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1312 - accuracy: 0.9586\n",
            "Epoch 100/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1338 - accuracy: 0.9574\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2811 - accuracy: 0.9338\n",
            "Try 3/100: Best_val_acc: [0.2810990512371063, 0.9337999820709229], lr: 0.0004544571470186765, Lambda: 0.0004061144128246624\n",
            "\n",
            "Epoch 1/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 1.3829 - accuracy: 0.5417\n",
            "Epoch 2/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.9020 - accuracy: 0.7162\n",
            "Epoch 3/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.7444 - accuracy: 0.7674\n",
            "Epoch 4/100\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 0.6712 - accuracy: 0.7896\n",
            "Epoch 5/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.6167 - accuracy: 0.8072\n",
            "Epoch 6/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.5771 - accuracy: 0.8186\n",
            "Epoch 7/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.5407 - accuracy: 0.8315\n",
            "Epoch 8/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.5259 - accuracy: 0.8365\n",
            "Epoch 9/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.4927 - accuracy: 0.8429\n",
            "Epoch 10/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.4732 - accuracy: 0.8518\n",
            "Epoch 11/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.4545 - accuracy: 0.8568\n",
            "Epoch 12/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.4439 - accuracy: 0.8591\n",
            "Epoch 13/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.4246 - accuracy: 0.8672\n",
            "Epoch 14/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.4110 - accuracy: 0.8700\n",
            "Epoch 15/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.4027 - accuracy: 0.8713\n",
            "Epoch 16/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3953 - accuracy: 0.8725\n",
            "Epoch 17/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3730 - accuracy: 0.8807\n",
            "Epoch 18/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3642 - accuracy: 0.8841\n",
            "Epoch 19/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3491 - accuracy: 0.8870\n",
            "Epoch 20/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3518 - accuracy: 0.8860\n",
            "Epoch 21/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3363 - accuracy: 0.8921\n",
            "Epoch 22/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3275 - accuracy: 0.8945\n",
            "Epoch 23/100\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 0.3218 - accuracy: 0.8962\n",
            "Epoch 24/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3117 - accuracy: 0.8985\n",
            "Epoch 25/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3159 - accuracy: 0.8971\n",
            "Epoch 26/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.3030 - accuracy: 0.9023\n",
            "Epoch 27/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2907 - accuracy: 0.9036\n",
            "Epoch 28/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2865 - accuracy: 0.9054\n",
            "Epoch 29/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2738 - accuracy: 0.9108\n",
            "Epoch 30/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2840 - accuracy: 0.9060\n",
            "Epoch 31/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2705 - accuracy: 0.9115\n",
            "Epoch 32/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2612 - accuracy: 0.9142\n",
            "Epoch 33/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2500 - accuracy: 0.9172\n",
            "Epoch 34/100\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 0.2650 - accuracy: 0.9146\n",
            "Epoch 35/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2568 - accuracy: 0.9157\n",
            "Epoch 36/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2505 - accuracy: 0.9167\n",
            "Epoch 37/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2397 - accuracy: 0.9217\n",
            "Epoch 38/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2357 - accuracy: 0.9215\n",
            "Epoch 39/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2357 - accuracy: 0.9219\n",
            "Epoch 40/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2252 - accuracy: 0.9245\n",
            "Epoch 41/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2242 - accuracy: 0.9251\n",
            "Epoch 42/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2187 - accuracy: 0.9269\n",
            "Epoch 43/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2173 - accuracy: 0.9268\n",
            "Epoch 44/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2154 - accuracy: 0.9279\n",
            "Epoch 45/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2162 - accuracy: 0.9273\n",
            "Epoch 46/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2002 - accuracy: 0.9343\n",
            "Epoch 47/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.2081 - accuracy: 0.9299\n",
            "Epoch 48/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1980 - accuracy: 0.9331\n",
            "Epoch 49/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1955 - accuracy: 0.9362\n",
            "Epoch 50/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1921 - accuracy: 0.9349\n",
            "Epoch 51/100\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 0.2009 - accuracy: 0.9332\n",
            "Epoch 52/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1936 - accuracy: 0.9343\n",
            "Epoch 53/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1862 - accuracy: 0.9369\n",
            "Epoch 54/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1842 - accuracy: 0.9371\n",
            "Epoch 55/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1836 - accuracy: 0.9376\n",
            "Epoch 56/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1728 - accuracy: 0.9412\n",
            "Epoch 57/100\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 0.1713 - accuracy: 0.9417\n",
            "Epoch 58/100\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 0.1680 - accuracy: 0.9434\n",
            "Epoch 59/100\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 0.1761 - accuracy: 0.9406\n",
            "Epoch 60/100\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 0.1736 - accuracy: 0.9421\n",
            "Epoch 61/100\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 0.1725 - accuracy: 0.9431\n",
            "Epoch 62/100\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 0.1624 - accuracy: 0.9457\n",
            "Epoch 63/100\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 0.1695 - accuracy: 0.9416\n",
            "Epoch 64/100\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 0.1607 - accuracy: 0.9454\n",
            "Epoch 65/100\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 0.1578 - accuracy: 0.9469\n",
            "Epoch 66/100\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 0.1677 - accuracy: 0.9422\n",
            "Epoch 67/100\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 0.1546 - accuracy: 0.9482\n",
            "Epoch 68/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1638 - accuracy: 0.9444\n",
            "Epoch 69/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1461 - accuracy: 0.9506\n",
            "Epoch 70/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1541 - accuracy: 0.9479\n",
            "Epoch 71/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1521 - accuracy: 0.9483\n",
            "Epoch 72/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1479 - accuracy: 0.9495\n",
            "Epoch 73/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1470 - accuracy: 0.9492\n",
            "Epoch 74/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1455 - accuracy: 0.9513\n",
            "Epoch 75/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1435 - accuracy: 0.9509\n",
            "Epoch 76/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1427 - accuracy: 0.9512\n",
            "Epoch 77/100\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 0.1502 - accuracy: 0.9478\n",
            "Epoch 78/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1356 - accuracy: 0.9538\n",
            "Epoch 79/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1356 - accuracy: 0.9531\n",
            "Epoch 80/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1361 - accuracy: 0.9535\n",
            "Epoch 81/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1421 - accuracy: 0.9508\n",
            "Epoch 82/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1383 - accuracy: 0.9524\n",
            "Epoch 83/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1276 - accuracy: 0.9570\n",
            "Epoch 84/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1313 - accuracy: 0.9549\n",
            "Epoch 85/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1329 - accuracy: 0.9539\n",
            "Epoch 86/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1338 - accuracy: 0.9535\n",
            "Epoch 87/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1311 - accuracy: 0.9544\n",
            "Epoch 88/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1273 - accuracy: 0.9569\n",
            "Epoch 89/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1218 - accuracy: 0.9582\n",
            "Epoch 90/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1310 - accuracy: 0.9550\n",
            "Epoch 91/100\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 0.1307 - accuracy: 0.9557\n",
            "Epoch 92/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1291 - accuracy: 0.9549\n",
            "Epoch 93/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1183 - accuracy: 0.9591\n",
            "Epoch 94/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1261 - accuracy: 0.9573\n",
            "Epoch 95/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1188 - accuracy: 0.9592\n",
            "Epoch 96/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1141 - accuracy: 0.9602\n",
            "Epoch 97/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1101 - accuracy: 0.9625\n",
            "Epoch 98/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1270 - accuracy: 0.9557\n",
            "Epoch 99/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1239 - accuracy: 0.9567\n",
            "Epoch 100/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1147 - accuracy: 0.9609\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3639 - accuracy: 0.9340\n",
            "Try 4/100: Best_val_acc: [0.3638949990272522, 0.9339666962623596], lr: 0.007501927798773922, Lambda: 0.007266653109964178\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1uNPkYo3tgE",
        "colab_type": "text"
      },
      "source": [
        "# Final Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbmhEkCvFIpn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mlp_model():\n",
        "    model = Sequential()\n",
        "    \n",
        "    model.add(Dense(128, input_shape = (1024, ), kernel_initializer='he_normal'))     # use he_normal initializer\n",
        "    model.add(BatchNormalization()) \n",
        "    model.add(Activation('relu'))    \n",
        "    model.add(Dense(128, kernel_initializer='he_normal'))                            # use he_normal initializer\n",
        "    model.add(BatchNormalization()) \n",
        "    model.add(Activation('relu'))    \n",
        "    model.add(Dense(10, kernel_initializer='he_normal'))                            # use he_normal initializer\n",
        "    model.add(Activation('softmax'))\n",
        "    \n",
        "    adam = optimizers.Adam(lr=1e-4, decay=1e-4)\n",
        "    model.compile(optimizer = adam, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLPhqFb8Grkm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a7e1274a-a90c-4099-df9b-d9441233e834"
      },
      "source": [
        "    # Fit the model\n",
        "    model.fit(X_train, y_train, epochs=100, batch_size=200, verbose= 1)\n",
        "    score = model.evaluate(X_val, y_val)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1164 - accuracy: 0.9607\n",
            "Epoch 2/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1172 - accuracy: 0.9600\n",
            "Epoch 3/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1067 - accuracy: 0.9640\n",
            "Epoch 4/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1090 - accuracy: 0.9627\n",
            "Epoch 5/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1068 - accuracy: 0.9649\n",
            "Epoch 6/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1057 - accuracy: 0.9651\n",
            "Epoch 7/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1013 - accuracy: 0.9669\n",
            "Epoch 8/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1004 - accuracy: 0.9665\n",
            "Epoch 9/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1142 - accuracy: 0.9621\n",
            "Epoch 10/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1092 - accuracy: 0.9634\n",
            "Epoch 11/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1054 - accuracy: 0.9651\n",
            "Epoch 12/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1031 - accuracy: 0.9656\n",
            "Epoch 13/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1002 - accuracy: 0.9653\n",
            "Epoch 14/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1071 - accuracy: 0.9639\n",
            "Epoch 15/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1011 - accuracy: 0.9664\n",
            "Epoch 16/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0969 - accuracy: 0.9676\n",
            "Epoch 17/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1028 - accuracy: 0.9655\n",
            "Epoch 18/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1042 - accuracy: 0.9645\n",
            "Epoch 19/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1017 - accuracy: 0.9651\n",
            "Epoch 20/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0940 - accuracy: 0.9683\n",
            "Epoch 21/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0950 - accuracy: 0.9683\n",
            "Epoch 22/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0935 - accuracy: 0.9690\n",
            "Epoch 23/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0963 - accuracy: 0.9686\n",
            "Epoch 24/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0972 - accuracy: 0.9677\n",
            "Epoch 25/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0963 - accuracy: 0.9680\n",
            "Epoch 26/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0950 - accuracy: 0.9680\n",
            "Epoch 27/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0888 - accuracy: 0.9706\n",
            "Epoch 28/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0956 - accuracy: 0.9682\n",
            "Epoch 29/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0936 - accuracy: 0.9687\n",
            "Epoch 30/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0925 - accuracy: 0.9688\n",
            "Epoch 31/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0943 - accuracy: 0.9684\n",
            "Epoch 32/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0932 - accuracy: 0.9695\n",
            "Epoch 33/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0880 - accuracy: 0.9707\n",
            "Epoch 34/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0902 - accuracy: 0.9695\n",
            "Epoch 35/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0861 - accuracy: 0.9710\n",
            "Epoch 36/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0901 - accuracy: 0.9704\n",
            "Epoch 37/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0859 - accuracy: 0.9707\n",
            "Epoch 38/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0852 - accuracy: 0.9715\n",
            "Epoch 39/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0870 - accuracy: 0.9700\n",
            "Epoch 40/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0800 - accuracy: 0.9735\n",
            "Epoch 41/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0897 - accuracy: 0.9697\n",
            "Epoch 42/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0912 - accuracy: 0.9693\n",
            "Epoch 43/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0831 - accuracy: 0.9719\n",
            "Epoch 44/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0795 - accuracy: 0.9733\n",
            "Epoch 45/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0784 - accuracy: 0.9737\n",
            "Epoch 46/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0867 - accuracy: 0.9703\n",
            "Epoch 47/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0859 - accuracy: 0.9708\n",
            "Epoch 48/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0794 - accuracy: 0.9730\n",
            "Epoch 49/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0850 - accuracy: 0.9713\n",
            "Epoch 50/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0750 - accuracy: 0.9745\n",
            "Epoch 51/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0829 - accuracy: 0.9718\n",
            "Epoch 52/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0861 - accuracy: 0.9704\n",
            "Epoch 53/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0806 - accuracy: 0.9729\n",
            "Epoch 54/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0887 - accuracy: 0.9694\n",
            "Epoch 55/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0828 - accuracy: 0.9717\n",
            "Epoch 56/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0704 - accuracy: 0.9767\n",
            "Epoch 57/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0816 - accuracy: 0.9727\n",
            "Epoch 58/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0829 - accuracy: 0.9720\n",
            "Epoch 59/100\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 0.0695 - accuracy: 0.9767\n",
            "Epoch 60/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0731 - accuracy: 0.9760\n",
            "Epoch 61/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0711 - accuracy: 0.9761\n",
            "Epoch 62/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0766 - accuracy: 0.9743\n",
            "Epoch 63/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0766 - accuracy: 0.9741\n",
            "Epoch 64/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0786 - accuracy: 0.9738\n",
            "Epoch 65/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0779 - accuracy: 0.9737\n",
            "Epoch 66/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0685 - accuracy: 0.9771\n",
            "Epoch 67/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0706 - accuracy: 0.9753\n",
            "Epoch 68/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0722 - accuracy: 0.9760\n",
            "Epoch 69/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0764 - accuracy: 0.9742\n",
            "Epoch 70/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0729 - accuracy: 0.9756\n",
            "Epoch 71/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0686 - accuracy: 0.9766\n",
            "Epoch 72/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0710 - accuracy: 0.9761\n",
            "Epoch 73/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0741 - accuracy: 0.9755\n",
            "Epoch 74/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0748 - accuracy: 0.9750\n",
            "Epoch 75/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0715 - accuracy: 0.9761\n",
            "Epoch 76/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0683 - accuracy: 0.9771\n",
            "Epoch 77/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0712 - accuracy: 0.9762\n",
            "Epoch 78/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0687 - accuracy: 0.9768\n",
            "Epoch 79/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0747 - accuracy: 0.9742\n",
            "Epoch 80/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0681 - accuracy: 0.9773\n",
            "Epoch 81/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0669 - accuracy: 0.9774\n",
            "Epoch 82/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0703 - accuracy: 0.9756\n",
            "Epoch 83/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0704 - accuracy: 0.9755\n",
            "Epoch 84/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0758 - accuracy: 0.9742\n",
            "Epoch 85/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0672 - accuracy: 0.9771\n",
            "Epoch 86/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0629 - accuracy: 0.9779\n",
            "Epoch 87/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0649 - accuracy: 0.9781\n",
            "Epoch 88/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0709 - accuracy: 0.9759\n",
            "Epoch 89/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0646 - accuracy: 0.9782\n",
            "Epoch 90/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0722 - accuracy: 0.9747\n",
            "Epoch 91/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0648 - accuracy: 0.9774\n",
            "Epoch 92/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0599 - accuracy: 0.9800\n",
            "Epoch 93/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0651 - accuracy: 0.9780\n",
            "Epoch 94/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0640 - accuracy: 0.9783\n",
            "Epoch 95/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0737 - accuracy: 0.9750\n",
            "Epoch 96/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0653 - accuracy: 0.9776\n",
            "Epoch 97/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0653 - accuracy: 0.9775\n",
            "Epoch 98/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0610 - accuracy: 0.9796\n",
            "Epoch 99/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0714 - accuracy: 0.9757\n",
            "Epoch 100/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0598 - accuracy: 0.9796\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3267 - accuracy: 0.9489\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnt7lMaLDnIe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e4f05b6f-9b6f-41a0-8cd7-fdbca513dac6"
      },
      "source": [
        "results = model.evaluate(X_val, y_val)\n",
        "print('Val_acc using NN Batch ADAM (Hyperparameters) : ', results[1])"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3267 - accuracy: 0.9489\n",
            "Val_acc using NN Batch ADAM (Hyperparameters) :  0.9489166736602783\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPbTkMXmD0CB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "d3f587bc-45a8-486f-91a8-da98806b3f31"
      },
      "source": [
        "#Store the accuracy results for each model in a dataframe for final comparison\n",
        "tempResultsDf = pd.DataFrame({'Method':['NN Batch ADAM (Hyperparameters)'], 'accuracy': [results[1]]},index={'4'})\n",
        "results_on_val= pd.concat([results_on_val, tempResultsDf])\n",
        "results_on_val = results_on_val[['Method', 'accuracy']]\n",
        "results_on_val"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Method</th>\n",
              "      <th>accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NN SDG</td>\n",
              "      <td>0.756950</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NN SGD (Batch Normalization)</td>\n",
              "      <td>0.756967</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NN ADAM (Batch Normalization)</td>\n",
              "      <td>0.939500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NN Batch ADAM (Hyperparameters)</td>\n",
              "      <td>0.948917</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                            Method  accuracy\n",
              "1                           NN SDG  0.756950\n",
              "2     NN SGD (Batch Normalization)  0.756967\n",
              "3    NN ADAM (Batch Normalization)  0.939500\n",
              "4  NN Batch ADAM (Hyperparameters)  0.948917"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-AU6QkBYOy-N",
        "colab_type": "text"
      },
      "source": [
        "So the best accuracy comes to 85% where learning rate is 1e-4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "diCo6MebI8uj",
        "colab_type": "text"
      },
      "source": [
        "# Include Dropout to avoid overfit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkrL2N9cIuDt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mlp_model():\n",
        "    model = Sequential()\n",
        "    \n",
        "    model.add(Dense(128, input_shape = (1024, ), kernel_initializer='he_normal'))     # use he_normal initializer\n",
        "    model.add(BatchNormalization()) \n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout(0.2))  \n",
        "    model.add(Dense(128, kernel_initializer='he_normal'))                            # use he_normal initializer\n",
        "    model.add(BatchNormalization()) \n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout(0.2)) \n",
        "    model.add(Dense(10, kernel_initializer='he_normal'))                            # use he_normal initializer\n",
        "    model.add(Activation('softmax'))\n",
        "    \n",
        "    adam = optimizers.Adam(lr=1e-4, decay=1e-4)\n",
        "    model.compile(optimizer = adam, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UoHLSP5zKwee",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "32bb56e2-07c4-464c-e9d3-7adfe2271521"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_12 (Dense)             (None, 128)               131200    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "activation_10 (Activation)   (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "activation_11 (Activation)   (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 10)                1290      \n",
            "_________________________________________________________________\n",
            "activation_12 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 150,026\n",
            "Trainable params: 149,514\n",
            "Non-trainable params: 512\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIVssdwrJgkr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a135c8ef-52c2-45a4-b11f-292ac9b2be98"
      },
      "source": [
        "    # Fit the model\n",
        "    model.fit(X_train, y_train, epochs=100, batch_size=200, verbose= 1)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0561 - accuracy: 0.9813\n",
            "Epoch 2/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0600 - accuracy: 0.9805\n",
            "Epoch 3/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0672 - accuracy: 0.9775\n",
            "Epoch 4/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0617 - accuracy: 0.9784\n",
            "Epoch 5/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0655 - accuracy: 0.9772\n",
            "Epoch 6/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0565 - accuracy: 0.9811\n",
            "Epoch 7/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0639 - accuracy: 0.9791\n",
            "Epoch 8/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0556 - accuracy: 0.9807\n",
            "Epoch 9/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0569 - accuracy: 0.9807\n",
            "Epoch 10/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0641 - accuracy: 0.9780\n",
            "Epoch 11/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0674 - accuracy: 0.9770\n",
            "Epoch 12/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0619 - accuracy: 0.9787\n",
            "Epoch 13/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0575 - accuracy: 0.9801\n",
            "Epoch 14/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0538 - accuracy: 0.9815\n",
            "Epoch 15/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0619 - accuracy: 0.9790\n",
            "Epoch 16/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0565 - accuracy: 0.9809\n",
            "Epoch 17/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0630 - accuracy: 0.9782\n",
            "Epoch 18/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0587 - accuracy: 0.9801\n",
            "Epoch 19/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0613 - accuracy: 0.9797\n",
            "Epoch 20/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0593 - accuracy: 0.9802\n",
            "Epoch 21/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0551 - accuracy: 0.9816\n",
            "Epoch 22/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0639 - accuracy: 0.9781\n",
            "Epoch 23/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0667 - accuracy: 0.9770\n",
            "Epoch 24/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0608 - accuracy: 0.9792\n",
            "Epoch 25/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0556 - accuracy: 0.9808\n",
            "Epoch 26/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0593 - accuracy: 0.9797\n",
            "Epoch 27/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0589 - accuracy: 0.9799\n",
            "Epoch 28/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0581 - accuracy: 0.9803\n",
            "Epoch 29/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0565 - accuracy: 0.9812\n",
            "Epoch 30/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0664 - accuracy: 0.9775\n",
            "Epoch 31/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0589 - accuracy: 0.9798\n",
            "Epoch 32/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0575 - accuracy: 0.9805\n",
            "Epoch 33/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0573 - accuracy: 0.9805\n",
            "Epoch 34/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0516 - accuracy: 0.9815\n",
            "Epoch 35/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0574 - accuracy: 0.9808\n",
            "Epoch 36/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0590 - accuracy: 0.9802\n",
            "Epoch 37/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0548 - accuracy: 0.9810\n",
            "Epoch 38/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0574 - accuracy: 0.9805\n",
            "Epoch 39/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0627 - accuracy: 0.9788\n",
            "Epoch 40/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0529 - accuracy: 0.9823\n",
            "Epoch 41/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0514 - accuracy: 0.9830\n",
            "Epoch 42/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0600 - accuracy: 0.9798\n",
            "Epoch 43/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0567 - accuracy: 0.9805\n",
            "Epoch 44/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0567 - accuracy: 0.9809\n",
            "Epoch 45/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0550 - accuracy: 0.9820\n",
            "Epoch 46/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0563 - accuracy: 0.9813\n",
            "Epoch 47/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0508 - accuracy: 0.9825\n",
            "Epoch 48/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0480 - accuracy: 0.9838\n",
            "Epoch 49/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0566 - accuracy: 0.9805\n",
            "Epoch 50/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0495 - accuracy: 0.9836\n",
            "Epoch 51/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0465 - accuracy: 0.9845\n",
            "Epoch 52/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0528 - accuracy: 0.9820\n",
            "Epoch 53/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0477 - accuracy: 0.9833\n",
            "Epoch 54/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0498 - accuracy: 0.9826\n",
            "Epoch 55/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0590 - accuracy: 0.9793\n",
            "Epoch 56/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0487 - accuracy: 0.9834\n",
            "Epoch 57/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0480 - accuracy: 0.9836\n",
            "Epoch 58/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0572 - accuracy: 0.9811\n",
            "Epoch 59/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0548 - accuracy: 0.9814\n",
            "Epoch 60/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0535 - accuracy: 0.9818\n",
            "Epoch 61/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0491 - accuracy: 0.9834\n",
            "Epoch 62/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0476 - accuracy: 0.9838\n",
            "Epoch 63/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0550 - accuracy: 0.9814\n",
            "Epoch 64/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0460 - accuracy: 0.9842\n",
            "Epoch 65/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0534 - accuracy: 0.9821\n",
            "Epoch 66/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0562 - accuracy: 0.9805\n",
            "Epoch 67/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0518 - accuracy: 0.9820\n",
            "Epoch 68/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0533 - accuracy: 0.9813\n",
            "Epoch 69/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0503 - accuracy: 0.9830\n",
            "Epoch 70/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0526 - accuracy: 0.9820\n",
            "Epoch 71/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0496 - accuracy: 0.9833\n",
            "Epoch 72/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0437 - accuracy: 0.9859\n",
            "Epoch 73/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0550 - accuracy: 0.9813\n",
            "Epoch 74/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0551 - accuracy: 0.9816\n",
            "Epoch 75/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0482 - accuracy: 0.9832\n",
            "Epoch 76/100\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 0.0442 - accuracy: 0.9851\n",
            "Epoch 77/100\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 0.0487 - accuracy: 0.9839\n",
            "Epoch 78/100\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 0.0553 - accuracy: 0.9813\n",
            "Epoch 79/100\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 0.0511 - accuracy: 0.9826\n",
            "Epoch 80/100\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 0.0436 - accuracy: 0.9849\n",
            "Epoch 81/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0472 - accuracy: 0.9845\n",
            "Epoch 82/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0504 - accuracy: 0.9818\n",
            "Epoch 83/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0491 - accuracy: 0.9833\n",
            "Epoch 84/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0525 - accuracy: 0.9824\n",
            "Epoch 85/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0511 - accuracy: 0.9828\n",
            "Epoch 86/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0499 - accuracy: 0.9831\n",
            "Epoch 87/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0501 - accuracy: 0.9836\n",
            "Epoch 88/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0438 - accuracy: 0.9848\n",
            "Epoch 89/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0445 - accuracy: 0.9845\n",
            "Epoch 90/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0494 - accuracy: 0.9828\n",
            "Epoch 91/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0516 - accuracy: 0.9826\n",
            "Epoch 92/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0461 - accuracy: 0.9838\n",
            "Epoch 93/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0464 - accuracy: 0.9844\n",
            "Epoch 94/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0463 - accuracy: 0.9843\n",
            "Epoch 95/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0473 - accuracy: 0.9841\n",
            "Epoch 96/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0512 - accuracy: 0.9826\n",
            "Epoch 97/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0494 - accuracy: 0.9828\n",
            "Epoch 98/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0443 - accuracy: 0.9845\n",
            "Epoch 99/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0488 - accuracy: 0.9840\n",
            "Epoch 100/100\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.0414 - accuracy: 0.9863\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc9ce1d8518>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CcDVI579Jvre",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "bf0a8f04-a634-499a-f354-eaad751782a7"
      },
      "source": [
        "results = model.evaluate(X_val, y_val)\n",
        "print('Val_acc using NN Batch ADAM (Dropout) : ', results[1])"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3719 - accuracy: 0.9492\n",
            "Val_acc using NN Batch ADAM (Dropout) :  0.9491999745368958\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22_0NujWJ1qn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "97fe0014-b8ee-4129-e77d-4e216cf90c61"
      },
      "source": [
        "#Store the accuracy results for each model in a dataframe for final comparison\n",
        "tempResultsDf = pd.DataFrame({'Method':['NN Batch ADAM (Dropout)'], 'accuracy': [results[1]]},index={'5'})\n",
        "results_on_val= pd.concat([results_on_val, tempResultsDf])\n",
        "results_on_val = results_on_val[['Method', 'accuracy']]\n",
        "results_on_val"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Method</th>\n",
              "      <th>accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NN SDG</td>\n",
              "      <td>0.756950</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NN SGD (Batch Normalization)</td>\n",
              "      <td>0.756967</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NN ADAM (Batch Normalization)</td>\n",
              "      <td>0.939500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NN Batch ADAM (Hyperparameters)</td>\n",
              "      <td>0.948917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>NN Batch ADAM (Dropout)</td>\n",
              "      <td>0.949200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                            Method  accuracy\n",
              "1                           NN SDG  0.756950\n",
              "2     NN SGD (Batch Normalization)  0.756967\n",
              "3    NN ADAM (Batch Normalization)  0.939500\n",
              "4  NN Batch ADAM (Hyperparameters)  0.948917\n",
              "5          NN Batch ADAM (Dropout)  0.949200"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QptJzI3NREDP",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation - Using the Testing Data Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3qdnFHgOJm4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "6381372e-3fca-4dc4-b83b-2045db817ebd"
      },
      "source": [
        "results = model.evaluate(X_test, y_test)\n",
        "print('Val_acc using NN Batch ADAM Dropout(Test_Data) : ', results[1])"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "563/563 [==============================] - 2s 3ms/step - loss: 1.1956 - accuracy: 0.8426\n",
            "Val_acc using NN Batch ADAM Dropout(Test_Data) :  0.8426111340522766\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mk_H3AUdM6wu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "ef02826d-dd62-4529-cdc2-30cdc192ed4c"
      },
      "source": [
        "#Store the accuracy results for each model in a dataframe for final comparison\n",
        "tempResultsDf = pd.DataFrame({'Method':['NN Batch ADAM Dropout(Test_Data)'], 'accuracy': [results[1]]},index={'6'})\n",
        "results_on_val= pd.concat([results_on_val, tempResultsDf])\n",
        "results_on_val = results_on_val[['Method', 'accuracy']]\n",
        "results_on_val"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Method</th>\n",
              "      <th>accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NN SDG</td>\n",
              "      <td>0.756950</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NN SGD (Batch Normalization)</td>\n",
              "      <td>0.756967</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NN ADAM (Batch Normalization)</td>\n",
              "      <td>0.939500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NN Batch ADAM (Hyperparameters)</td>\n",
              "      <td>0.948917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>NN Batch ADAM (Dropout)</td>\n",
              "      <td>0.949200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>NN Batch ADAM Dropout(Test_Data)</td>\n",
              "      <td>0.842611</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                             Method  accuracy\n",
              "1                            NN SDG  0.756950\n",
              "2      NN SGD (Batch Normalization)  0.756967\n",
              "3     NN ADAM (Batch Normalization)  0.939500\n",
              "4   NN Batch ADAM (Hyperparameters)  0.948917\n",
              "5           NN Batch ADAM (Dropout)  0.949200\n",
              "6  NN Batch ADAM Dropout(Test_Data)  0.842611"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhpMnm2cOyi5",
        "colab_type": "text"
      },
      "source": [
        "# Predicting Images using Testing Data Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cs9Y-vsP-_A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "9596eb3f-3cd4-4e7d-a4c8-4673d009d79e"
      },
      "source": [
        "#Predicting for all images\n",
        "y_pred=model.predict_classes(X_test)\n",
        "print(y_pred)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-52-68ec98cdf36b>:2: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
            "Instructions for updating:\n",
            "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "[1 7 2 ... 7 9 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cro4EbZmPBGx",
        "colab_type": "text"
      },
      "source": [
        "#### Image 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYVwI7FtL47Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "7d40b94d-93d6-4ce8-ca2f-6903c9a16047"
      },
      "source": [
        "#Showing the image\n",
        "plt.imshow(X_test[1].reshape(32,32),cmap='gray')"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fc970fd1c50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSO-JDwXL7Wj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "47657844-1fa6-40f8-c622-2ddd759e910e"
      },
      "source": [
        "#Predicting the digits\n",
        "y_pred[1]"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fyMAti9nPD_E",
        "colab_type": "text"
      },
      "source": [
        "#### Image 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcjadSvyPDTg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "4aee0698-75bb-42d3-b6e4-69feaa327ad1"
      },
      "source": [
        "#Showing the image\n",
        "plt.imshow(X_test[12000].reshape(32,32),cmap='gray')"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fc974ebaa90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPMtMimlPMDf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5ef8573e-9d99-4494-896a-91a2a66fec57"
      },
      "source": [
        "#Predicting the digits\n",
        "y_pred[12000]"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xnf2JBfjPUr-",
        "colab_type": "text"
      },
      "source": [
        "#### Image 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAoHR_AMPUGv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "9300a25e-c432-4db0-91b7-ede5b3ed83e0"
      },
      "source": [
        "#Showing the image\n",
        "plt.imshow(X_test[17999].reshape(32,32),cmap='gray')"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fc974e708d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2myD9dePhHm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4c4c8c9d-42b3-40c7-a325-d4304f238db3"
      },
      "source": [
        "#Predicting the digits\n",
        "y_pred[17999]"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5eJK9E9AU3yI",
        "colab_type": "text"
      },
      "source": [
        "#### Image 4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncckC85iU28t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "801b9583-98de-4fd4-bc21-299d5496d5c9"
      },
      "source": [
        "#Showing the image\n",
        "plt.imshow(X_test[3000].reshape(32,32),cmap='gray')"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fc97509cf60>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59Rl8twEVES3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "196bb3e8-90e7-409f-d64c-66021a10ed7b"
      },
      "source": [
        "#Predicting the digits\n",
        "y_pred[3000]"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZ9APnsYTblh",
        "colab_type": "text"
      },
      "source": [
        "## Confusion matrix demonstrating the accuracy of the classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "weH82YuegoDR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "outputId": "71fbd976-9b44-43da-a72c-fe8188be7a76"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "# Set the figure size\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "# Calculate the confusion matrix\n",
        "cm = confusion_matrix(y_true=np.argmax(y_test, axis=1), y_pred=y_pred)\n",
        "\n",
        "# Normalize the confusion matrix\n",
        "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100.0\n",
        "\n",
        "# Visualize the confusion matrix\n",
        "sns.heatmap(cm, annot=True, cmap='Reds', fmt='.1f', square=True);"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCCYw4Nq-jFb",
        "colab_type": "text"
      },
      "source": [
        "## Classification Report demonstrating the accuracy of the classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KY6QmWTU-Aym",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "b3e0e1de-ea1e-4278-aee4-2b2a5b31e211"
      },
      "source": [
        "print(classification_report(y_true=np.argmax(y_test, axis=1), y_pred=y_pred))"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.88      0.87      1814\n",
            "           1       0.84      0.85      0.85      1828\n",
            "           2       0.90      0.85      0.87      1803\n",
            "           3       0.81      0.80      0.80      1719\n",
            "           4       0.89      0.87      0.88      1812\n",
            "           5       0.85      0.82      0.83      1768\n",
            "           6       0.78      0.84      0.81      1832\n",
            "           7       0.88      0.88      0.88      1808\n",
            "           8       0.79      0.82      0.80      1812\n",
            "           9       0.85      0.82      0.83      1804\n",
            "\n",
            "    accuracy                           0.84     18000\n",
            "   macro avg       0.84      0.84      0.84     18000\n",
            "weighted avg       0.84      0.84      0.84     18000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UiENKRQjTxcp",
        "colab_type": "text"
      },
      "source": [
        "# Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtD8tLvuDvDu",
        "colab_type": "text"
      },
      "source": [
        "* Neural Network model was trained with the Street View House Numbers (SVHN) Dataset.\n",
        "\n",
        "* Started with Simple Feed Forward Neural Network with Sigmoid and Optimizer as Stochastic Gradient Descent (SGD) with initialization weight which gave really low accuracy and high loss in training data.\n",
        "\n",
        "* Moved to RELU  and then with optimizer as ADAM which bumped up the accuracy and also reduced the loss.\n",
        "\n",
        "* Then tries with many hyperparameters(Hidden Layers, Hidden Units,learning Rate, Number of Epochs, activations Functions).\n",
        "\n",
        "* Using Deep Deural Betwork with Batch Normalization, hyper parameter tuning and 20% dropout  This resulted a tremendous improvement and finally got 85% accuracy on validation data and close to 80% accuracy on the Testing data set.\n",
        "\n",
        "* The predicting of the images from the testing data set depitcs the images correctly.\n",
        "\n",
        "* Classification report and Confusion matrix depicts clearly that single digit from SVHN is predicted with pretty high accuracy using the final model. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsYQGhKYYACP",
        "colab_type": "text"
      },
      "source": [
        "### Thank you"
      ]
    }
  ]
}